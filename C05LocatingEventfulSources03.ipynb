{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ebcbd4-b225-4cf5-a630-55d719816f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth ---\n",
      "\n",
      "--- Starting Search ---\n",
      "\n",
      ">>> ENTERING STAGE 0 (Slack Epsilon = 2.0) <<<\n",
      "   Iter 0: Loss 0.70650\n",
      "      Est: Pos=[4.90, 5.10] Vel=[-5.00, 5.00]\n",
      "   Iter 10: Loss 0.65549\n",
      "      Est: Pos=[3.91, 6.09] Vel=[-54.23, 54.30]\n",
      "   Iter 20: Loss 0.62788\n",
      "      Est: Pos=[3.04, 6.97] Vel=[-97.33, 98.10]\n",
      "   Iter 30: Loss 0.62065\n",
      "      Est: Pos=[2.44, 7.61] Vel=[-125.68, 128.66]\n",
      "   Iter 40: Loss 0.62066\n",
      "      Est: Pos=[2.19, 7.93] Vel=[-136.09, 142.57]\n",
      "   Iter 50: Loss 0.62081\n",
      "      Est: Pos=[2.18, 7.99] Vel=[-133.45, 143.25]\n",
      "   Iter 60: Loss 0.62048\n",
      "      Est: Pos=[2.28, 7.92] Vel=[-125.47, 137.19]\n",
      "   Iter 70: Loss 0.62031\n",
      "      Est: Pos=[2.36, 7.84] Vel=[-117.99, 130.03]\n",
      "   Iter 80: Loss 0.62029\n",
      "      Est: Pos=[2.38, 7.80] Vel=[-113.27, 124.75]\n",
      "   Iter 90: Loss 0.62027\n",
      "      Est: Pos=[2.35, 7.81] Vel=[-110.62, 121.62]\n",
      "\n",
      ">>> ENTERING STAGE 1 (Slack Epsilon = 0.5) <<<\n",
      "   Iter 0: Loss 0.66657\n",
      "      Est: Pos=[2.41, 7.75] Vel=[-104.04, 115.20]\n",
      "   Iter 10: Loss 0.30874\n",
      "      Est: Pos=[3.89, 6.21] Vel=[-27.42, 35.90]\n",
      "   Iter 20: Loss 0.25850\n",
      "      Est: Pos=[3.34, 6.67] Vel=[-50.58, 54.04]\n",
      "   Iter 30: Loss 0.26339\n",
      "      Est: Pos=[3.33, 6.75] Vel=[-41.92, 49.93]\n",
      "   Iter 40: Loss 0.26142\n",
      "      Est: Pos=[3.45, 6.62] Vel=[-26.16, 32.86]\n",
      "   Iter 50: Loss 0.25734\n",
      "      Est: Pos=[3.24, 6.81] Vel=[-26.17, 31.62]\n",
      "   Iter 60: Loss 0.25495\n",
      "      Est: Pos=[3.31, 6.77] Vel=[-11.98, 18.58]\n",
      "   Iter 70: Loss 0.25373\n",
      "      Est: Pos=[3.21, 6.85] Vel=[-6.39, 12.15]\n",
      "   Iter 80: Loss 0.25290\n",
      "      Est: Pos=[3.19, 6.87] Vel=[2.92, 2.74]\n",
      "   Iter 90: Loss 0.25219\n",
      "      Est: Pos=[3.15, 6.92] Vel=[10.81, -5.19]\n",
      "\n",
      ">>> ENTERING STAGE 2 (Slack Epsilon = 0.0) <<<\n",
      "   Iter 0: Loss 0.00120\n",
      "      Est: Pos=[3.11, 6.96] Vel=[18.50, -13.09]\n",
      "   Iter 10: Loss 0.00070\n",
      "      Est: Pos=[3.06, 6.99] Vel=[26.98, -18.59]\n",
      "   Iter 20: Loss 0.00051\n",
      "      Est: Pos=[3.03, 7.01] Vel=[34.05, -21.12]\n",
      "   Iter 30: Loss 0.00046\n",
      "      Est: Pos=[3.01, 7.01] Vel=[38.41, -21.81]\n",
      "   Iter 40: Loss 0.00046\n",
      "      Est: Pos=[3.00, 7.01] Vel=[40.46, -21.55]\n",
      "   Iter 50: Loss 0.00046\n",
      "      Est: Pos=[2.99, 7.00] Vel=[41.02, -20.98]\n",
      "   Iter 60: Loss 0.00045\n",
      "      Est: Pos=[3.00, 7.00] Vel=[40.89, -20.46]\n",
      "   Iter 70: Loss 0.00045\n",
      "      Est: Pos=[3.00, 7.00] Vel=[40.55, -20.12]\n",
      "   Iter 80: Loss 0.00045\n",
      "      Est: Pos=[3.00, 7.00] Vel=[40.25, -19.97]\n",
      "   Iter 90: Loss 0.00045\n",
      "      Est: Pos=[3.00, 7.00] Vel=[40.07, -19.94]\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Estimated: Pos=[3.000016 6.999794] Vel=[ 40.004173 -19.962263]\n",
      "True     : Pos=[3. 7.] Vel=[ 40. -20.]\n",
      "Pos Error: 0.0002 m\n",
      "Vel Error: 0.0380 m/s\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "import optax\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. SETUP\n",
    "# ==============================================================================\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "C_SOUND = 343.0\n",
    "DURATION_STEPS = 1200 # Increased to 0.12s to help velocity tracking\n",
    "\n",
    "IDX_P = 0\n",
    "IDX_VX = 1\n",
    "IDX_VY = 2\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. STABLE MACCORMACK KERNEL\n",
    "# ==============================================================================\n",
    "\n",
    "@jit\n",
    "def get_gradients_fwd(u):\n",
    "    u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "    u_center = u_pad[1:-1, 1:-1]\n",
    "    \n",
    "    # Forward Diff\n",
    "    d_dy = (u_pad[2:, 1:-1] - u_center) / DX\n",
    "    d_dx = (u_pad[1:-1, 2:] - u_center) / DX\n",
    "    \n",
    "    lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + \\\n",
    "           u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_center) / (DX**2)\n",
    "    return d_dx, d_dy, lap\n",
    "\n",
    "@jit\n",
    "def get_gradients_bwd(u):\n",
    "    u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "    u_center = u_pad[1:-1, 1:-1]\n",
    "    \n",
    "    # Backward Diff\n",
    "    d_dy = (u_center - u_pad[0:-2, 1:-1]) / DX\n",
    "    d_dx = (u_center - u_pad[1:-1, 0:-2]) / DX\n",
    "        \n",
    "    lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + \\\n",
    "           u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_center) / (DX**2)\n",
    "    return d_dx, d_dy, lap\n",
    "\n",
    "@jit\n",
    "def physics_update(u, d_dx, d_dy, lap, epsilon):\n",
    "    delta = jnp.zeros_like(u)\n",
    "    div_v = d_dx[..., IDX_VX] + d_dy[..., IDX_VY]\n",
    "    \n",
    "    rate_p = -C_SOUND * div_v + epsilon * lap[..., IDX_P]\n",
    "    rate_vx = -C_SOUND * d_dx[..., IDX_P] + epsilon * lap[..., IDX_VX]\n",
    "    rate_vy = -C_SOUND * d_dy[..., IDX_P] + epsilon * lap[..., IDX_VY]\n",
    "    \n",
    "    delta = delta.at[..., IDX_P].set(rate_p)\n",
    "    delta = delta.at[..., IDX_VX].set(rate_vx)\n",
    "    delta = delta.at[..., IDX_VY].set(rate_vy)\n",
    "    return delta\n",
    "\n",
    "@jit\n",
    "def full_step_maccormack(u, epsilon):\n",
    "    d_dx_f, d_dy_f, lap = get_gradients_fwd(u)\n",
    "    rate_pred = physics_update(u, d_dx_f, d_dy_f, lap, epsilon)\n",
    "    u_pred = u + rate_pred * DT\n",
    "    \n",
    "    d_dx_b, d_dy_b, lap_b = get_gradients_bwd(u_pred)\n",
    "    rate_corr = physics_update(u_pred, d_dx_b, d_dy_b, lap_b, epsilon)\n",
    "    \n",
    "    u_next = 0.5 * (u + u_pred + rate_corr * DT)\n",
    "    \n",
    "    # Hard Wall Boundaries\n",
    "    u_next = u_next.at[0, :, :].set(0)\n",
    "    u_next = u_next.at[-1, :, :].set(0)\n",
    "    u_next = u_next.at[:, 0, :].set(0)\n",
    "    u_next = u_next.at[:, -1, :].set(0)\n",
    "    \n",
    "    return u_next\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. SIMULATION LOOP (With Split Params)\n",
    "# ==============================================================================\n",
    "\n",
    "@jit\n",
    "def run_simulation(params_dict, epsilon):\n",
    "    # Unpack Dictionary\n",
    "    pos = params_dict['pos']\n",
    "    vel = params_dict['vel']\n",
    "    \n",
    "    x0, y0 = pos[0], pos[1]\n",
    "    vx, vy = vel[0], vel[1]\n",
    "    \n",
    "    xs = jnp.linspace(0, GRID_SIZE*DX, GRID_SIZE)\n",
    "    ys = jnp.linspace(0, GRID_SIZE*DX, GRID_SIZE)\n",
    "    X, Y = jnp.meshgrid(xs, ys, indexing='xy')\n",
    "    \n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, 3))\n",
    "    \n",
    "    # Blob Size\n",
    "    blob_width = 0.5 + epsilon * 2.0\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_curr = carry\n",
    "        current_time = step_idx * DT\n",
    "        \n",
    "        # Physics\n",
    "        u_next = full_step_maccormack(u_curr, epsilon)\n",
    "        \n",
    "        # Moving Source\n",
    "        pos_x = x0 + vx * current_time\n",
    "        pos_y = y0 + vy * current_time\n",
    "        \n",
    "        # Injection\n",
    "        dist_sq = (X - pos_x)**2 + (Y - pos_y)**2\n",
    "        spatial = jnp.exp(-dist_sq / (2 * blob_width**2))\n",
    "        \n",
    "        # Temporal \"Ping\" (Gaussian in time)\n",
    "        # Peak at step 50, width 20\n",
    "        amplitude = jnp.exp(-(step_idx - 50)**2 / (2 * 20.0**2)) * 100.0\n",
    "        \n",
    "        source = spatial * amplitude * DT\n",
    "        u_next = u_next.at[..., IDX_P].add(source)\n",
    "        \n",
    "        return u_next, u_next[..., IDX_P]\n",
    "\n",
    "    final_u, history_p = lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))\n",
    "    return history_p\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. INVERSE SOLVER (Differential Learning Rates)\n",
    "# ==============================================================================\n",
    "\n",
    "# True State: Moves [3, 7] -> [40, -20]\n",
    "TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0])}\n",
    "\n",
    "SENSORS_RC = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "\n",
    "print(f\"--- Generating Ground Truth ---\")\n",
    "true_history = run_simulation(TRUE_PARAMS, epsilon=0.0)\n",
    "observed_data = true_history[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "\n",
    "def loss_fn(est_params_dict, epsilon):\n",
    "    sim_hist = run_simulation(est_params_dict, epsilon)\n",
    "    sim_data = sim_hist[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "    \n",
    "    # Normalize (Correlation)\n",
    "    safe_eps = 1e-6\n",
    "    sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "    obs_norm = (observed_data - jnp.mean(observed_data, 0)) / (jnp.std(observed_data, 0) + safe_eps)\n",
    "    \n",
    "    corr = jnp.mean(sim_norm * obs_norm)\n",
    "    \n",
    "    # Boundary Penalty (Position Only)\n",
    "    pos = est_params_dict['pos']\n",
    "    bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "    \n",
    "    return (1.0 - corr) + bounds\n",
    "\n",
    "def solve():\n",
    "    # Initial Guess: Static at Center\n",
    "    guess = {\n",
    "        'pos': jnp.array([5.0, 5.0]),\n",
    "        'vel': jnp.array([0.0, 0.0])\n",
    "    }\n",
    "    \n",
    "    # DIFFERENTIAL LEARNING RATES\n",
    "    # Velocity gets a 50x multiplier to match Position gradients\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {\n",
    "                'pos': optax.adam(0.1),\n",
    "                'vel': optax.adam(5.0)  # The Fix: 5.0 LR for Velocity\n",
    "            },\n",
    "            param_labels=lambda p: 'vel' if 'vel' in str(p) else 'pos' # Simple mapping won't work on dict keys directly in newer optax\n",
    "            # We map manually below\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Manual Mapping for optax.multi_transform on Dicts\n",
    "    # We define the transform structure to match the params dict structure\n",
    "    partition_optimizers = {\n",
    "        'pos': optax.adam(0.1),\n",
    "        'vel': optax.adam(5.0)\n",
    "    }\n",
    "    \n",
    "    # Correct way to apply multi_transform to a PyTree (Dict)\n",
    "    # We assign labels matching the keys\n",
    "    param_spec = {'pos': 'pos', 'vel': 'vel'}\n",
    "    \n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(partition_optimizers, param_spec)\n",
    "    )\n",
    "\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    epsilon_schedule = [2.0, 0.5, 0.0]\n",
    "    \n",
    "    print(f\"\\n--- Starting Search ---\")\n",
    "    \n",
    "    for stage, eps in enumerate(epsilon_schedule):\n",
    "        print(f\"\\n>>> ENTERING STAGE {stage} (Slack Epsilon = {eps}) <<<\")\n",
    "        for i in range(100): \n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                p = guess['pos']\n",
    "                v = guess['vel']\n",
    "                print(f\"   Iter {i}: Loss {loss:.5f}\")\n",
    "                print(f\"      Est: Pos=[{p[0]:.2f}, {p[1]:.2f}] Vel=[{v[0]:.2f}, {v[1]:.2f}]\")\n",
    "                \n",
    "    print(f\"\\n--- FINAL RESULT ---\")\n",
    "    p_final = guess['pos']\n",
    "    v_final = guess['vel']\n",
    "    \n",
    "    print(f\"Estimated: Pos={p_final} Vel={v_final}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "    \n",
    "    pos_err = jnp.linalg.norm(p_final - TRUE_PARAMS['pos'])\n",
    "    vel_err = jnp.linalg.norm(v_final - TRUE_PARAMS['vel'])\n",
    "    \n",
    "    print(f\"Pos Error: {pos_err:.4f} m\")\n",
    "    print(f\"Vel Error: {vel_err:.4f} m/s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a201dd-f1fa-48a5-b5a8-613025d4f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "from typing import NamedTuple, Callable\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. THE MODEL ABSTRACTION (The \"Local\" Physics)\n",
    "# ==============================================================================\n",
    "\n",
    "class PhysParams(NamedTuple):\n",
    "    c: float\n",
    "    epsilon: float\n",
    "\n",
    "def acoustic_constitutive_law(u_state, grads, laplacian, params: PhysParams):\n",
    "    \"\"\"\n",
    "    PURE PHYSICS. No grids, no loops, no padding.\n",
    "    \n",
    "    Inputs:\n",
    "      u_state:   [P, Vx, Vy] at a specific point (or vectorized)\n",
    "      grads:     ([dP/dx, dVx/dx, dVy/dx], [dP/dy, dVx/dy, dVy/dy])\n",
    "      laplacian: [Lap_P, Lap_Vx, Lap_Vy]\n",
    "      params:    Physical constants (Speed of sound, Slack)\n",
    "      \n",
    "    Returns:\n",
    "      d_state/dt: [Rate_P, Rate_Vx, Rate_Vy]\n",
    "    \"\"\"\n",
    "    # Unpack State (for readability)\n",
    "    # 0: Pressure, 1: Vx, 2: Vy\n",
    "    \n",
    "    # Unpack Gradients\n",
    "    # d_dx[0] is dP/dx, d_dx[1] is dVx/dx, etc.\n",
    "    d_dx, d_dy = grads\n",
    "    \n",
    "    # --- THE PHYSICAL EQUATIONS ---\n",
    "    # 1. Mass Conservation: dP/dt = -c * Div(V) + diffusion\n",
    "    div_v = d_dx[1] + d_dy[2] # d(Vx)/dx + d(Vy)/dy\n",
    "    rate_p = -params.c * div_v + params.epsilon * laplacian[0]\n",
    "    \n",
    "    # 2. Momentum Conservation X: dVx/dt = -c * Grad(P)_x + diffusion\n",
    "    grad_p_x = d_dx[0]\n",
    "    rate_vx = -params.c * grad_p_x + params.epsilon * laplacian[1]\n",
    "    \n",
    "    # 3. Momentum Conservation Y: dVy/dt = -c * Grad(P)_y + diffusion\n",
    "    grad_p_y = d_dy[0]\n",
    "    rate_vy = -params.c * grad_p_y + params.epsilon * laplacian[2]\n",
    "    \n",
    "    # Pack Result\n",
    "    return jnp.stack([rate_p, rate_vx, rate_vy], axis=-1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THE TOPOLOGY ENGINE (The Grid)\n",
    "# ==============================================================================\n",
    "\n",
    "@jit\n",
    "def calculate_stencil(u, dx):\n",
    "    \"\"\"\n",
    "    Calculates Forward and Backward spatial derivatives using Hard Walls.\n",
    "    Returns a NamedTuple-like structure or just raw tuples of gradients.\n",
    "    \"\"\"\n",
    "    # Pad for Hard Walls: ((BeforeY, AfterY), (BeforeX, AfterX), (Ch))\n",
    "    u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "    u_center = u_pad[1:-1, 1:-1]\n",
    "    \n",
    "    # --- Forward Gradients (Predictor) ---\n",
    "    # d/dy (Rows, Axis 0)\n",
    "    dy_fwd = (u_pad[2:, 1:-1] - u_center) / dx\n",
    "    # d/dx (Cols, Axis 1)\n",
    "    dx_fwd = (u_pad[1:-1, 2:] - u_center) / dx\n",
    "    \n",
    "    # --- Backward Gradients (Corrector) ---\n",
    "    dy_bwd = (u_center - u_pad[0:-2, 1:-1]) / dx\n",
    "    dx_bwd = (u_center - u_pad[1:-1, 0:-2]) / dx\n",
    "    \n",
    "    # --- Laplacian (Central) ---\n",
    "    lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + \\\n",
    "           u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_center) / (dx**2)\n",
    "           \n",
    "    return (dx_fwd, dy_fwd), (dx_bwd, dy_bwd), lap\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. THE INTEGRATOR (The Solver)\n",
    "# ==============================================================================\n",
    "\n",
    "@jit\n",
    "def maccormack_integrator(u, dt, dx, params: PhysParams, physics_fn: Callable):\n",
    "    \"\"\"\n",
    "    Generic Predictor-Corrector Integrator.\n",
    "    It doesn't know it's solving acoustics. It just calls 'physics_fn'.\n",
    "    \"\"\"\n",
    "    # 1. Get Geometry\n",
    "    grads_fwd, grads_bwd, lap = calculate_stencil(u, dx)\n",
    "    \n",
    "    # 2. Predictor Step (Using Forward Gradients)\n",
    "    # physics_fn(u, (d_dx, d_dy), lap, params)\n",
    "    k1 = physics_fn(u, grads_fwd, lap, params)\n",
    "    u_pred = u + k1 * dt\n",
    "    \n",
    "    # 3. Corrector Step (Using Backward Gradients on Predicted State)\n",
    "    # We must re-calculate gradients on the PREDICTED state\n",
    "    # Note: We only need Backward gradients here, but our helper gets both.\n",
    "    # Optimization: In pure JIT, unused outputs are pruned.\n",
    "    _, grads_bwd_pred, lap_pred = calculate_stencil(u_pred, dx)\n",
    "    \n",
    "    k2 = physics_fn(u_pred, grads_bwd_pred, lap_pred, params)\n",
    "    \n",
    "    # 4. Update\n",
    "    u_next = 0.5 * (u + u_pred + k2 * dt)\n",
    "    \n",
    "    # 5. Boundary Enforcement (Hard Walls)\n",
    "    u_next = u_next.at[0, :, :].set(0)\n",
    "    u_next = u_next.at[-1, :, :].set(0)\n",
    "    u_next = u_next.at[:, 0, :].set(0)\n",
    "    u_next = u_next.at[:, -1, :].set(0)\n",
    "    \n",
    "    return u_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e56f3e7-785d-4ee9-a888-9626bf6e09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth ---\n",
      "\n",
      "--- Starting Search ---\n",
      "\n",
      ">>> ENTERING STAGE 0 (Slack Epsilon = 2.0) <<<\n",
      "   Iter 0: Loss 0.70650 | Pos=[4.90, 5.10] Vel=[-5.00, 5.00]\n",
      "   Iter 10: Loss 0.65549 | Pos=[3.91, 6.09] Vel=[-54.23, 54.30]\n",
      "   Iter 20: Loss 0.62788 | Pos=[3.04, 6.97] Vel=[-97.33, 98.10]\n",
      "   Iter 30: Loss 0.62065 | Pos=[2.44, 7.61] Vel=[-125.68, 128.66]\n",
      "   Iter 40: Loss 0.62066 | Pos=[2.19, 7.93] Vel=[-136.09, 142.57]\n",
      "   Iter 50: Loss 0.62081 | Pos=[2.18, 7.99] Vel=[-133.45, 143.25]\n",
      "   Iter 60: Loss 0.62048 | Pos=[2.28, 7.92] Vel=[-125.47, 137.19]\n",
      "   Iter 70: Loss 0.62031 | Pos=[2.36, 7.84] Vel=[-117.99, 130.03]\n",
      "   Iter 80: Loss 0.62029 | Pos=[2.38, 7.80] Vel=[-113.27, 124.75]\n",
      "   Iter 90: Loss 0.62027 | Pos=[2.35, 7.81] Vel=[-110.62, 121.62]\n",
      "\n",
      ">>> ENTERING STAGE 1 (Slack Epsilon = 0.5) <<<\n",
      "   Iter 0: Loss 0.66657 | Pos=[2.41, 7.75] Vel=[-104.04, 115.20]\n",
      "   Iter 10: Loss 0.30874 | Pos=[3.89, 6.21] Vel=[-27.42, 35.90]\n",
      "   Iter 20: Loss 0.25850 | Pos=[3.34, 6.67] Vel=[-50.58, 54.04]\n",
      "   Iter 30: Loss 0.26339 | Pos=[3.33, 6.75] Vel=[-41.92, 49.93]\n",
      "   Iter 40: Loss 0.26142 | Pos=[3.45, 6.62] Vel=[-26.16, 32.86]\n",
      "   Iter 50: Loss 0.25734 | Pos=[3.24, 6.81] Vel=[-26.17, 31.62]\n",
      "   Iter 60: Loss 0.25495 | Pos=[3.31, 6.77] Vel=[-11.98, 18.58]\n",
      "   Iter 70: Loss 0.25373 | Pos=[3.21, 6.85] Vel=[-6.39, 12.15]\n",
      "   Iter 80: Loss 0.25290 | Pos=[3.19, 6.87] Vel=[2.92, 2.74]\n",
      "   Iter 90: Loss 0.25219 | Pos=[3.15, 6.92] Vel=[10.81, -5.19]\n",
      "\n",
      ">>> ENTERING STAGE 2 (Slack Epsilon = 0.0) <<<\n",
      "   Iter 0: Loss 0.00120 | Pos=[3.11, 6.96] Vel=[18.50, -13.09]\n",
      "   Iter 10: Loss 0.00070 | Pos=[3.06, 6.99] Vel=[26.98, -18.59]\n",
      "   Iter 20: Loss 0.00051 | Pos=[3.03, 7.01] Vel=[34.05, -21.12]\n",
      "   Iter 30: Loss 0.00046 | Pos=[3.01, 7.01] Vel=[38.41, -21.81]\n",
      "   Iter 40: Loss 0.00046 | Pos=[3.00, 7.01] Vel=[40.46, -21.55]\n",
      "   Iter 50: Loss 0.00046 | Pos=[2.99, 7.00] Vel=[41.02, -20.98]\n",
      "   Iter 60: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.89, -20.46]\n",
      "   Iter 70: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.55, -20.12]\n",
      "   Iter 80: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.25, -19.97]\n",
      "   Iter 90: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.07, -19.94]\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Estimated: Pos=[3.000016 6.999794] Vel=[ 40.004154 -19.962255]\n",
      "True     : Pos=[3. 7.] Vel=[ 40. -20.]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "from typing import NamedTuple, Callable, Tuple\n",
    "import optax\n",
    "import functools # Import needed for partial/wraps if manual, but static_argnames is easier\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. THE PHYSICS MODEL\n",
    "# ==============================================================================\n",
    "IDX_P, IDX_VX, IDX_VY = 0, 1, 2\n",
    "\n",
    "class PhysParams(NamedTuple):\n",
    "    c: float\n",
    "    epsilon: float\n",
    "\n",
    "@jit\n",
    "def acoustic_constitutive_law(u, grads: Tuple, laplacian, params: PhysParams):\n",
    "    d_dx, d_dy = grads\n",
    "    \n",
    "    # 1. Mass: dP/dt = -c * Div(V)\n",
    "    div_v = d_dx[..., IDX_VX] + d_dy[..., IDX_VY]\n",
    "    rate_p = -params.c * div_v + params.epsilon * laplacian[..., IDX_P]\n",
    "    \n",
    "    # 2. Momentum X: d(Vx)/dt = -c * dP/dx\n",
    "    grad_p_x = d_dx[..., IDX_P]\n",
    "    rate_vx = -params.c * grad_p_x + params.epsilon * laplacian[..., IDX_VX]\n",
    "    \n",
    "    # 3. Momentum Y: d(Vy)/dt = -c * dP/dy\n",
    "    grad_p_y = d_dy[..., IDX_P]\n",
    "    rate_vy = -params.c * grad_p_y + params.epsilon * laplacian[..., IDX_VY]\n",
    "    \n",
    "    return jnp.stack([rate_p, rate_vx, rate_vy], axis=-1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THE TOPOLOGY ENGINE\n",
    "# ==============================================================================\n",
    "\n",
    "@jit\n",
    "def calculate_stencil(u, dx):\n",
    "    \"\"\" Calculates Forward/Backward gradients + Laplacian with Hard Wall padding \"\"\"\n",
    "    u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "    u_center = u_pad[1:-1, 1:-1]\n",
    "    \n",
    "    # Forward Gradients\n",
    "    dx_fwd = (u_pad[1:-1, 2:] - u_center) / dx\n",
    "    dy_fwd = (u_pad[2:, 1:-1] - u_center) / dx\n",
    "    \n",
    "    # Backward Gradients\n",
    "    dx_bwd = (u_center - u_pad[1:-1, 0:-2]) / dx\n",
    "    dy_bwd = (u_center - u_pad[0:-2, 1:-1]) / dx\n",
    "    \n",
    "    # Laplacian\n",
    "    lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + \\\n",
    "           u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_center) / (dx**2)\n",
    "           \n",
    "    return (dx_fwd, dy_fwd), (dx_bwd, dy_bwd), lap\n",
    "\n",
    "# FIX: Added static_argnames=['model_fn']\n",
    "@functools.partial(jit, static_argnames=['model_fn'])\n",
    "def maccormack_step(u, dt, dx, params: PhysParams, model_fn: Callable):\n",
    "    \"\"\"\n",
    "    Generic Predictor-Corrector.\n",
    "    model_fn is marked STATIC so JAX doesn't try to trace it as an array.\n",
    "    \"\"\"\n",
    "    # 1. Geometry\n",
    "    grads_fwd, grads_bwd, lap = calculate_stencil(u, dx)\n",
    "    \n",
    "    # 2. Predictor\n",
    "    k1 = model_fn(u, grads_fwd, lap, params)\n",
    "    u_pred = u + k1 * dt\n",
    "    \n",
    "    # 3. Corrector (re-calc gradients on prediction)\n",
    "    _, grads_bwd_pred, lap_pred = calculate_stencil(u_pred, dx)\n",
    "    k2 = model_fn(u_pred, grads_bwd_pred, lap_pred, params)\n",
    "    \n",
    "    # 4. Update\n",
    "    u_next = 0.5 * (u + u_pred + k2 * dt)\n",
    "    \n",
    "    # 5. Boundaries (Hard Walls)\n",
    "    u_next = u_next.at[0, :, :].set(0)\n",
    "    u_next = u_next.at[-1, :, :].set(0)\n",
    "    u_next = u_next.at[:, 0, :].set(0)\n",
    "    u_next = u_next.at[:, -1, :].set(0)\n",
    "    \n",
    "    return u_next\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. SIMULATION RUNNER\n",
    "# ==============================================================================\n",
    "\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "DURATION_STEPS = 1200 \n",
    "\n",
    "@jit\n",
    "def run_simulation(params_dict, epsilon):\n",
    "    x0, y0 = params_dict['pos'][0], params_dict['pos'][1]\n",
    "    vx, vy = params_dict['vel'][0], params_dict['vel'][1]\n",
    "    \n",
    "    phys_params = PhysParams(c=343.0, epsilon=epsilon)\n",
    "    \n",
    "    xs = jnp.linspace(0, GRID_SIZE*DX, GRID_SIZE)\n",
    "    ys = jnp.linspace(0, GRID_SIZE*DX, GRID_SIZE)\n",
    "    X, Y = jnp.meshgrid(xs, ys, indexing='xy')\n",
    "    \n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, 3))\n",
    "    \n",
    "    blob_width = 0.5 + epsilon * 2.0\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_curr = carry\n",
    "        \n",
    "        # A. INTEGRATE (Pass the function!)\n",
    "        u_next = maccormack_step(u_curr, DT, DX, phys_params, acoustic_constitutive_law)\n",
    "        \n",
    "        # B. FORCING\n",
    "        current_time = step_idx * DT\n",
    "        pos_x = x0 + vx * current_time\n",
    "        pos_y = y0 + vy * current_time\n",
    "        \n",
    "        dist_sq = (X - pos_x)**2 + (Y - pos_y)**2\n",
    "        spatial = jnp.exp(-dist_sq / (2 * blob_width**2))\n",
    "        amplitude = jnp.exp(-(step_idx - 50)**2 / (2 * 20.0**2)) * 100.0\n",
    "        \n",
    "        source = spatial * amplitude * DT\n",
    "        u_next = u_next.at[..., IDX_P].add(source)\n",
    "        \n",
    "        return u_next, u_next[..., IDX_P]\n",
    "\n",
    "    final_u, history_p = lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))\n",
    "    return history_p\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. INVERSE SOLVER\n",
    "# ==============================================================================\n",
    "\n",
    "TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0])}\n",
    "SENSORS_RC = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "\n",
    "print(f\"--- Generating Ground Truth ---\")\n",
    "true_history = run_simulation(TRUE_PARAMS, epsilon=0.0)\n",
    "observed_data = true_history[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "\n",
    "def loss_fn(est_params_dict, epsilon):\n",
    "    sim_hist = run_simulation(est_params_dict, epsilon)\n",
    "    sim_data = sim_hist[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "    \n",
    "    safe_eps = 1e-6\n",
    "    sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "    obs_norm = (observed_data - jnp.mean(observed_data, 0)) / (jnp.std(observed_data, 0) + safe_eps)\n",
    "    corr = jnp.mean(sim_norm * obs_norm)\n",
    "    \n",
    "    pos = est_params_dict['pos']\n",
    "    bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "    return (1.0 - corr) + bounds\n",
    "\n",
    "def solve():\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0])}\n",
    "    \n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {'pos': optax.adam(0.1), 'vel': optax.adam(5.0)},\n",
    "            {'pos': 'pos', 'vel': 'vel'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    epsilon_schedule = [2.0, 0.5, 0.0]\n",
    "    \n",
    "    print(f\"\\n--- Starting Search ---\")\n",
    "    for stage, eps in enumerate(epsilon_schedule):\n",
    "        print(f\"\\n>>> ENTERING STAGE {stage} (Slack Epsilon = {eps}) <<<\")\n",
    "        for i in range(100): \n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                p = guess['pos']\n",
    "                v = guess['vel']\n",
    "                print(f\"   Iter {i}: Loss {loss:.5f} | Pos=[{p[0]:.2f}, {p[1]:.2f}] Vel=[{v[0]:.2f}, {v[1]:.2f}]\")\n",
    "\n",
    "    print(f\"\\n--- FINAL RESULT ---\")\n",
    "    print(f\"Estimated: Pos={guess['pos']} Vel={guess['vel']}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad3bab8-68d8-401d-a91e-4e040e3b41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth (Matrix Algebra) ---\n",
      "\n",
      "--- Starting Search ---\n",
      "\n",
      ">>> ENTERING STAGE 0 (Slack Epsilon = 2.0) <<<\n",
      "   Iter 0: Loss 0.74853 | Pos=[4.90, 5.10] Vel=[-5.00, 5.00]\n",
      "   Iter 10: Loss 0.70204 | Pos=[3.91, 6.09] Vel=[-54.20, 54.27]\n",
      "   Iter 20: Loss 0.67788 | Pos=[3.05, 6.96] Vel=[-96.74, 97.62]\n",
      "   Iter 30: Loss 0.67248 | Pos=[2.48, 7.58] Vel=[-123.16, 126.72]\n",
      "   Iter 40: Loss 0.67281 | Pos=[2.27, 7.87] Vel=[-130.56, 138.31]\n",
      "   Iter 50: Loss 0.67279 | Pos=[2.31, 7.90] Vel=[-125.14, 136.69]\n",
      "   Iter 60: Loss 0.67242 | Pos=[2.42, 7.82] Vel=[-115.51, 129.00]\n",
      "   Iter 70: Loss 0.67230 | Pos=[2.50, 7.74] Vel=[-107.61, 121.06]\n",
      "   Iter 80: Loss 0.67228 | Pos=[2.50, 7.72] Vel=[-103.03, 115.49]\n",
      "   Iter 90: Loss 0.67225 | Pos=[2.45, 7.74] Vel=[-100.28, 112.00]\n",
      "\n",
      ">>> ENTERING STAGE 1 (Slack Epsilon = 0.5) <<<\n",
      "   Iter 0: Loss 0.62616 | Pos=[2.50, 7.68] Vel=[-93.08, 104.82]\n",
      "   Iter 10: Loss 0.33514 | Pos=[3.87, 6.21] Vel=[-22.23, 28.81]\n",
      "   Iter 20: Loss 0.27620 | Pos=[3.22, 6.77] Vel=[-48.83, 51.39]\n",
      "   Iter 30: Loss 0.27285 | Pos=[3.41, 6.73] Vel=[-29.87, 40.70]\n",
      "   Iter 40: Loss 0.27277 | Pos=[3.35, 6.68] Vel=[-22.92, 27.98]\n",
      "   Iter 50: Loss 0.27124 | Pos=[3.25, 6.82] Vel=[-17.46, 25.10]\n",
      "   Iter 60: Loss 0.26974 | Pos=[3.28, 6.79] Vel=[-5.30, 13.26]\n",
      "   Iter 70: Loss 0.26866 | Pos=[3.18, 6.87] Vel=[-0.17, 7.08]\n",
      "   Iter 80: Loss 0.26786 | Pos=[3.18, 6.89] Vel=[9.94, -1.79]\n",
      "   Iter 90: Loss 0.26722 | Pos=[3.12, 6.94] Vel=[16.33, -8.98]\n",
      "\n",
      ">>> ENTERING STAGE 2 (Slack Epsilon = 0.0) <<<\n",
      "   Iter 0: Loss 0.00114 | Pos=[3.09, 6.97] Vel=[24.26, -16.37]\n",
      "   Iter 10: Loss 0.00064 | Pos=[3.05, 7.00] Vel=[31.63, -20.88]\n",
      "   Iter 20: Loss 0.00048 | Pos=[3.02, 7.01] Vel=[37.16, -22.26]\n",
      "   Iter 30: Loss 0.00045 | Pos=[3.00, 7.01] Vel=[40.14, -22.05]\n",
      "   Iter 40: Loss 0.00045 | Pos=[3.00, 7.01] Vel=[41.17, -21.32]\n",
      "   Iter 50: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[41.11, -20.61]\n",
      "   Iter 60: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.69, -20.15]\n",
      "   Iter 70: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.29, -19.94]\n",
      "   Iter 80: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.05, -19.90]\n",
      "   Iter 90: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[39.96, -19.94]\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Estimated: Pos=[3.0001287 6.99991  ] Vel=[ 39.95883  -19.987885]\n",
      "True     : Pos=[3. 7.] Vel=[ 40. -20.]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "from typing import NamedTuple, Callable, List\n",
    "import optax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. THE MATRIX-ALGEBRA BRIDGE (Robust & Fast)\n",
    "# ==============================================================================\n",
    "\n",
    "class MatrixAlgebra:\n",
    "    \"\"\"\n",
    "    Pre-computes the Geometric Product matrices for the basis vectors.\n",
    "    Allows performing 'e_i * Field' using pure linear algebra (matmul).\n",
    "    \"\"\"\n",
    "    def __init__(self, p, q, r=0):\n",
    "        self.p, self.q, self.r = p, q, r\n",
    "        self.alg = Algebra(p, q, r)\n",
    "        self.dim = len(self.alg) # Should be 2^(p+q+r)\n",
    "        \n",
    "        # 1. Identify Basis Vectors (e1, e2...) to iterate over in the physics loop\n",
    "        # We need the 1-vectors (generators).\n",
    "        # We access them safely via the blades dict.\n",
    "        self.basis_names = [f'e{i+1}' for i in range(p + q + r)]\n",
    "        \n",
    "        # 2. Generate Multiplication Matrices\n",
    "        # For each generator e_k, we compute a matrix M_k.\n",
    "        \n",
    "        matrices = []\n",
    "        for name in self.basis_names:\n",
    "            e_k = self.alg.blades[name] # The generator (e.g., e1)\n",
    "            \n",
    "            # Build matrix column-by-column\n",
    "            # Column j corresponds to the result of (e_k * basis_blade_j)\n",
    "            cols = []\n",
    "            for i in range(self.dim):\n",
    "                # Robustly create the i-th canonical basis blade (1, e1, e2, e12...)\n",
    "                # Index i maps to binary representation of blades.\n",
    "                b_i = self.alg.multivector({i: 1})\n",
    "                \n",
    "                # Geometric Product: e_k * b_i\n",
    "                res = e_k * b_i\n",
    "                \n",
    "                # Extract dense coefficients into a JAX array column\n",
    "                dense_col = jnp.zeros(self.dim)\n",
    "                \n",
    "                # Kingdon multivectors are sparse dictionaries (key: value)\n",
    "                # We iterate the keys (indices) in the result\n",
    "                for bin_key, val in res.items():\n",
    "                    # bin_key is the integer index of the blade (e.g., 3 for e12)\n",
    "                    # We map this directly to the dense array index\n",
    "                    dense_col = dense_col.at[bin_key].set(val)\n",
    "                        \n",
    "                cols.append(dense_col)\n",
    "            \n",
    "            # Stack columns to form (dim, dim) matrix for generator e_k\n",
    "            M = jnp.stack(cols, axis=1)\n",
    "            matrices.append(M)\n",
    "            \n",
    "        # Store as a JAX array stack: Shape (Spatial_Dim, Algebra_Dim, Algebra_Dim)\n",
    "        self.basis_matrices = jnp.stack(matrices)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.p, self.q, self.r))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.p, self.q, self.r) == (other.p, other.q, other.r)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THE PHYSICS KERNEL (Matrix-Based)\n",
    "# ==============================================================================\n",
    "\n",
    "IDX_P, IDX_VX, IDX_VY = 0, 1, 2\n",
    "\n",
    "class PhysParams(NamedTuple):\n",
    "    c: float\n",
    "    epsilon: float\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra'])\n",
    "def geometric_constitutive_law(u_coeffs, grads_list: List, lap_coeffs, params: PhysParams, algebra: MatrixAlgebra):\n",
    "    \"\"\"\n",
    "    GENERIC STA PHYSICS (Matrix Implementation).\n",
    "    Equation: d(Psi)/dt = -c * sum( M_i @ d_i(Psi) )\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Initialize Rate (same shape as u)\n",
    "    rate_coeffs = jnp.zeros_like(u_coeffs)\n",
    "    \n",
    "    # 2. Geometric Derivative Loop\n",
    "    # We iterate over the spatial dimensions\n",
    "    for i, grad_coeffs in enumerate(grads_list):\n",
    "        if i >= len(algebra.basis_matrices): break\n",
    "        \n",
    "        # Get the pre-computed multiplication matrix for e_i\n",
    "        # Shape: (Alg_Dim, Alg_Dim)\n",
    "        M_i = algebra.basis_matrices[i]\n",
    "        \n",
    "        # Apply Matrix to Field: basis * gradient\n",
    "        # grad_coeffs shape: (Grid, Grid, Alg_Dim)\n",
    "        # We want to contract the last dimension\n",
    "        # term = jnp.dot(grad_coeffs, M_i.T) \n",
    "        # But let's be explicit with einsum for clarity:\n",
    "        # \"...j\" is input field component\n",
    "        # \"kj\" is matrix (row k, col j) -> This is M @ v standard? \n",
    "        # No, M @ v means M_kj * v_j -> result_k.\n",
    "        term = jnp.einsum('kj,...j->...k', M_i, grad_coeffs)\n",
    "        \n",
    "        rate_coeffs = rate_coeffs - params.c * term\n",
    "        \n",
    "    # 3. Geometric Slack (Scalar multiplication, no matrix needed)\n",
    "    rate_coeffs = rate_coeffs + params.epsilon * lap_coeffs\n",
    "    \n",
    "    return rate_coeffs\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. THE TOPOLOGY ENGINE (Grid)\n",
    "# ==============================================================================\n",
    "\n",
    "@functools.partial(jit, static_argnames=['ndim'])\n",
    "def get_gradients_general(u, dx, ndim):\n",
    "    \"\"\" N-dim Finite Difference \"\"\"\n",
    "    pad_width = tuple([(1, 1)] * ndim + [(0, 0)])\n",
    "    u_pad = jnp.pad(u, pad_width, mode='constant')\n",
    "    \n",
    "    center_slice = tuple([slice(1, -1)] * ndim + [slice(None)])\n",
    "    u_center = u_pad[center_slice]\n",
    "    \n",
    "    raw_grads_fwd = []\n",
    "    raw_grads_bwd = []\n",
    "    lap_sum = jnp.zeros_like(u_center)\n",
    "    \n",
    "    for axis in range(ndim):\n",
    "        slice_fwd = [slice(1, -1)] * ndim; slice_fwd[axis] = slice(2, None); slice_fwd.append(slice(None))\n",
    "        slice_bwd = [slice(1, -1)] * ndim; slice_bwd[axis] = slice(0, -2); slice_bwd.append(slice(None))\n",
    "        \n",
    "        u_fwd = u_pad[tuple(slice_fwd)]\n",
    "        u_bwd = u_pad[tuple(slice_bwd)]\n",
    "        \n",
    "        d_fwd = (u_fwd - u_center) / dx\n",
    "        d_bwd = (u_center - u_bwd) / dx\n",
    "        \n",
    "        raw_grads_fwd.append(d_fwd)\n",
    "        raw_grads_bwd.append(d_bwd)\n",
    "        lap_sum += (u_fwd + u_bwd - 2*u_center) / (dx**2)\n",
    "    \n",
    "    # Reorder [d/dY, d/dX] -> [d/dX, d/dY]\n",
    "    if ndim == 2:\n",
    "        grads_fwd = [raw_grads_fwd[1], raw_grads_fwd[0]]\n",
    "        grads_bwd = [raw_grads_bwd[1], raw_grads_bwd[0]]\n",
    "    else:\n",
    "        grads_fwd = raw_grads_fwd\n",
    "        grads_bwd = raw_grads_bwd\n",
    "        \n",
    "    return grads_fwd, grads_bwd, lap_sum\n",
    "\n",
    "@functools.partial(jit, static_argnames=['model_fn', 'algebra', 'ndim'])\n",
    "def maccormack_step(u, dt, dx, params: PhysParams, model_fn: Callable, algebra: MatrixAlgebra, ndim: int):\n",
    "    # Pass 'algebra' (the wrapper) down\n",
    "    grads_fwd, grads_bwd, lap = get_gradients_general(u, dx, ndim)\n",
    "    \n",
    "    k1 = model_fn(u, grads_fwd, lap, params, algebra)\n",
    "    u_pred = u + k1 * dt\n",
    "    \n",
    "    _, grads_bwd_pred, lap_pred = get_gradients_general(u_pred, dx, ndim)\n",
    "    k2 = model_fn(u_pred, grads_bwd_pred, lap_pred, params, algebra)\n",
    "    \n",
    "    u_next = 0.5 * (u + u_pred + k2 * dt)\n",
    "    \n",
    "    for axis in range(ndim):\n",
    "        s0 = [slice(None)] * (ndim + 1); s0[axis] = 0; u_next = u_next.at[tuple(s0)].set(0)\n",
    "        s1 = [slice(None)] * (ndim + 1); s1[axis] = -1; u_next = u_next.at[tuple(s1)].set(0)\n",
    "    \n",
    "    return u_next\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. SIMULATION RUNNER\n",
    "# ==============================================================================\n",
    "\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "DURATION_STEPS = 1200 \n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra'])\n",
    "def run_simulation(params_dict, epsilon, algebra: MatrixAlgebra):\n",
    "    xs = jnp.linspace(0, GRID_SIZE*DX, GRID_SIZE)\n",
    "    ys = jnp.linspace(0, GRID_SIZE*DX, GRID_SIZE)\n",
    "    X, Y = jnp.meshgrid(xs, ys, indexing='xy')\n",
    "    \n",
    "    # Use algebra.dim (e.g., 4 for 2D, 8 for 3D)\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    \n",
    "    phys_params = PhysParams(c=343.0, epsilon=epsilon)\n",
    "    x0, y0 = params_dict['pos'][0], params_dict['pos'][1]\n",
    "    vx, vy = params_dict['vel'][0], params_dict['vel'][1]\n",
    "    blob_width = 0.5 + epsilon * 2.0\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_curr = carry\n",
    "        \n",
    "        u_next = maccormack_step(\n",
    "            u_curr, DT, DX, phys_params, \n",
    "            geometric_constitutive_law, \n",
    "            algebra, # Passing matrix wrapper\n",
    "            ndim=2\n",
    "        )\n",
    "        \n",
    "        current_time = step_idx * DT\n",
    "        pos_x = x0 + vx * current_time\n",
    "        pos_y = y0 + vy * current_time\n",
    "        dist_sq = (X - pos_x)**2 + (Y - pos_y)**2\n",
    "        source = jnp.exp(-dist_sq / (2 * blob_width**2)) * jnp.exp(-(step_idx - 50)**2 / (2 * 20.0**2)) * 100.0 * DT\n",
    "        \n",
    "        u_next = u_next.at[..., IDX_P].add(source)\n",
    "        return u_next, u_next[..., IDX_P]\n",
    "\n",
    "    final_u, history_p = lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))\n",
    "    return history_p\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "def solve():\n",
    "    # 1. Define World (Matrix Algebra Wrapper)\n",
    "    world_2d = MatrixAlgebra(2, 0)\n",
    "    \n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0])}\n",
    "    SENSORS_RC = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "\n",
    "    print(f\"--- Generating Ground Truth (Matrix Algebra) ---\")\n",
    "    true_history = run_simulation(TRUE_PARAMS, epsilon=0.0, algebra=world_2d)\n",
    "    observed_data = true_history[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "\n",
    "    def loss_fn(est_params, epsilon):\n",
    "        sim_hist = run_simulation(est_params, epsilon, algebra=world_2d)\n",
    "        sim_data = sim_hist[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "        \n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (observed_data - jnp.mean(observed_data, 0)) / (jnp.std(observed_data, 0) + safe_eps)\n",
    "        \n",
    "        corr = jnp.mean(sim_norm * obs_norm)\n",
    "        pos = est_params['pos']\n",
    "        bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "        return (1.0 - corr) + bounds\n",
    "\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0])}\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {'pos': optax.adam(0.1), 'vel': optax.adam(5.0)},\n",
    "            {'pos': 'pos', 'vel': 'vel'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    print(f\"\\n--- Starting Search ---\")\n",
    "    for stage, eps in enumerate([2.0, 0.5, 0.0]):\n",
    "        print(f\"\\n>>> ENTERING STAGE {stage} (Slack Epsilon = {eps}) <<<\")\n",
    "        for i in range(100): \n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            if i % 10 == 0:\n",
    "                p, v = guess['pos'], guess['vel']\n",
    "                print(f\"   Iter {i}: Loss {loss:.5f} | Pos=[{p[0]:.2f}, {p[1]:.2f}] Vel=[{v[0]:.2f}, {v[1]:.2f}]\")\n",
    "\n",
    "    print(f\"\\n--- FINAL RESULT ---\")\n",
    "    print(f\"Estimated: Pos={guess['pos']} Vel={guess['vel']}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6728c8b-73cf-4e0c-b413-47aa6e47705e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth (CartesianBox) ---\n",
      "\n",
      "--- Starting Search ---\n",
      "\n",
      ">>> ENTERING STAGE 0 (Slack Epsilon = 2.0) <<<\n",
      "   Iter 0: Loss 0.74853 | Pos=[4.90, 5.10] Vel=[-5.00, 5.00]\n",
      "   Iter 10: Loss 0.70204 | Pos=[3.91, 6.09] Vel=[-54.20, 54.27]\n",
      "   Iter 20: Loss 0.67788 | Pos=[3.05, 6.96] Vel=[-96.74, 97.62]\n",
      "   Iter 30: Loss 0.67248 | Pos=[2.48, 7.58] Vel=[-123.16, 126.72]\n",
      "   Iter 40: Loss 0.67281 | Pos=[2.27, 7.87] Vel=[-130.56, 138.31]\n",
      "   Iter 50: Loss 0.67279 | Pos=[2.31, 7.90] Vel=[-125.14, 136.69]\n",
      "   Iter 60: Loss 0.67242 | Pos=[2.42, 7.82] Vel=[-115.51, 129.00]\n",
      "   Iter 70: Loss 0.67230 | Pos=[2.50, 7.74] Vel=[-107.61, 121.06]\n",
      "   Iter 80: Loss 0.67228 | Pos=[2.50, 7.72] Vel=[-103.03, 115.49]\n",
      "   Iter 90: Loss 0.67225 | Pos=[2.45, 7.74] Vel=[-100.28, 112.00]\n",
      "\n",
      ">>> ENTERING STAGE 1 (Slack Epsilon = 0.5) <<<\n",
      "   Iter 0: Loss 0.62616 | Pos=[2.50, 7.68] Vel=[-93.08, 104.82]\n",
      "   Iter 10: Loss 0.33514 | Pos=[3.87, 6.21] Vel=[-22.23, 28.81]\n",
      "   Iter 20: Loss 0.27620 | Pos=[3.22, 6.77] Vel=[-48.83, 51.39]\n",
      "   Iter 30: Loss 0.27285 | Pos=[3.41, 6.73] Vel=[-29.87, 40.70]\n",
      "   Iter 40: Loss 0.27277 | Pos=[3.35, 6.68] Vel=[-22.92, 27.98]\n",
      "   Iter 50: Loss 0.27124 | Pos=[3.25, 6.82] Vel=[-17.46, 25.10]\n",
      "   Iter 60: Loss 0.26974 | Pos=[3.28, 6.79] Vel=[-5.30, 13.26]\n",
      "   Iter 70: Loss 0.26866 | Pos=[3.18, 6.87] Vel=[-0.17, 7.08]\n",
      "   Iter 80: Loss 0.26786 | Pos=[3.18, 6.89] Vel=[9.94, -1.79]\n",
      "   Iter 90: Loss 0.26722 | Pos=[3.12, 6.94] Vel=[16.33, -8.98]\n",
      "\n",
      ">>> ENTERING STAGE 2 (Slack Epsilon = 0.0) <<<\n",
      "   Iter 0: Loss 0.00114 | Pos=[3.09, 6.97] Vel=[24.26, -16.37]\n",
      "   Iter 10: Loss 0.00064 | Pos=[3.05, 7.00] Vel=[31.63, -20.88]\n",
      "   Iter 20: Loss 0.00048 | Pos=[3.02, 7.01] Vel=[37.16, -22.26]\n",
      "   Iter 30: Loss 0.00045 | Pos=[3.00, 7.01] Vel=[40.14, -22.05]\n",
      "   Iter 40: Loss 0.00045 | Pos=[3.00, 7.01] Vel=[41.17, -21.32]\n",
      "   Iter 50: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[41.11, -20.61]\n",
      "   Iter 60: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.69, -20.15]\n",
      "   Iter 70: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.29, -19.94]\n",
      "   Iter 80: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[40.05, -19.90]\n",
      "   Iter 90: Loss 0.00045 | Pos=[3.00, 7.00] Vel=[39.96, -19.94]\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Estimated: Pos=[3.0001287 6.9999104] Vel=[ 39.958828 -19.987833]\n",
      "True     : Pos=[3. 7.] Vel=[ 40. -20.]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "from typing import NamedTuple, Callable, List, Tuple\n",
    "import optax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. THE MANIFOLD ABSTRACTION (Topology)\n",
    "# ==============================================================================\n",
    "\n",
    "class Manifold:\n",
    "    \"\"\" Base class for Grid Topology \"\"\"\n",
    "    def __hash__(self): raise NotImplementedError\n",
    "    def __eq__(self, other): raise NotImplementedError\n",
    "    \n",
    "    def gradients(self, u): \n",
    "        \"\"\" Returns (fwd_grads_list, bwd_grads_list, laplacian) \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def enforce_boundaries(self, u):\n",
    "        \"\"\" Applies boundary conditions (walls, wrapping, etc.) \"\"\"\n",
    "        return u # Default: do nothing\n",
    "        \n",
    "    @property\n",
    "    def coordinates(self):\n",
    "        \"\"\" Returns coordinate meshgrids [X, Y, ...] \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class CartesianBox(Manifold):\n",
    "    \"\"\" Standard 2D Grid with Hard Wall Boundaries \"\"\"\n",
    "    def __init__(self, size, dx):\n",
    "        self.size = size\n",
    "        self.dx = dx\n",
    "        # Cache coordinates\n",
    "        xs = jnp.linspace(0, size*dx, size)\n",
    "        ys = jnp.linspace(0, size*dx, size)\n",
    "        self.X, self.Y = jnp.meshgrid(xs, ys, indexing='xy')\n",
    "        \n",
    "    def __hash__(self): return hash((self.size, self.dx, 'box'))\n",
    "    def __eq__(self, o): return (self.size, self.dx) == (o.size, o.dx) and isinstance(o, CartesianBox)\n",
    "    \n",
    "    @property\n",
    "    def coordinates(self): return (self.X, self.Y)\n",
    "\n",
    "    def gradients(self, u):\n",
    "        # Hard Wall Padding: ((Y_pre, Y_post), (X_pre, X_post), (Ch))\n",
    "        u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "        u_center = u_pad[1:-1, 1:-1]\n",
    "        dx = self.dx\n",
    "        \n",
    "        # d/dx (Axis 1) and d/dy (Axis 0)\n",
    "        # Forward\n",
    "        dx_fwd = (u_pad[1:-1, 2:] - u_center) / dx\n",
    "        dy_fwd = (u_pad[2:, 1:-1] - u_center) / dx\n",
    "        # Backward\n",
    "        dx_bwd = (u_center - u_pad[1:-1, 0:-2]) / dx\n",
    "        dy_bwd = (u_center - u_pad[0:-2, 1:-1]) / dx\n",
    "        # Laplacian\n",
    "        lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + \\\n",
    "               u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_center) / (dx**2)\n",
    "               \n",
    "        # Return matched lists: [d_x, d_y]\n",
    "        return ([dx_fwd, dy_fwd], [dx_bwd, dy_bwd], lap)\n",
    "\n",
    "    def enforce_boundaries(self, u):\n",
    "        # Zero out edges\n",
    "        u = u.at[0, :, :].set(0)\n",
    "        u = u.at[-1, :, :].set(0)\n",
    "        u = u.at[:, 0, :].set(0)\n",
    "        u = u.at[:, -1, :].set(0)\n",
    "        return u\n",
    "\n",
    "class CartesianTorus(Manifold):\n",
    "    \"\"\" 2D Grid with Periodic Boundaries (Pac-Man) \"\"\"\n",
    "    def __init__(self, size, dx):\n",
    "        self.size = size\n",
    "        self.dx = dx\n",
    "        xs = jnp.linspace(0, size*dx, size)\n",
    "        ys = jnp.linspace(0, size*dx, size)\n",
    "        self.X, self.Y = jnp.meshgrid(xs, ys, indexing='xy')\n",
    "\n",
    "    def __hash__(self): return hash((self.size, self.dx, 'torus'))\n",
    "    def __eq__(self, o): return (self.size, self.dx) == (o.size, o.dx) and isinstance(o, CartesianTorus)\n",
    "\n",
    "    @property\n",
    "    def coordinates(self): return (self.X, self.Y)\n",
    "\n",
    "    def gradients(self, u):\n",
    "        # Periodic Wrapping via jnp.roll (No padding needed!)\n",
    "        dx = self.dx\n",
    "        \n",
    "        # Forward\n",
    "        dx_fwd = (jnp.roll(u, -1, axis=1) - u) / dx\n",
    "        dy_fwd = (jnp.roll(u, -1, axis=0) - u) / dx\n",
    "        # Backward\n",
    "        dx_bwd = (u - jnp.roll(u, 1, axis=1)) / dx\n",
    "        dy_bwd = (u - jnp.roll(u, 1, axis=0)) / dx\n",
    "        # Laplacian\n",
    "        lap = (jnp.roll(u, -1, axis=1) + jnp.roll(u, 1, axis=1) + \\\n",
    "               jnp.roll(u, -1, axis=0) + jnp.roll(u, 1, axis=0) - 4*u) / (dx**2)\n",
    "               \n",
    "        return ([dx_fwd, dy_fwd], [dx_bwd, dy_bwd], lap)\n",
    "        \n",
    "    def enforce_boundaries(self, u):\n",
    "        return u # No edges to enforce!\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. MATRIX ALGEBRA (Unchanged)\n",
    "# ==============================================================================\n",
    "class MatrixAlgebra:\n",
    "    def __init__(self, p, q, r=0):\n",
    "        self.p, self.q, self.r = p, q, r\n",
    "        self.alg = Algebra(p, q, r)\n",
    "        self.dim = len(self.alg)\n",
    "        self.basis_names = [f'e{i+1}' for i in range(p + q + r)]\n",
    "        \n",
    "        matrices = []\n",
    "        for name in self.basis_names:\n",
    "            e_k = self.alg.blades[name]\n",
    "            cols = []\n",
    "            for i in range(self.dim):\n",
    "                b_i = self.alg.multivector({i: 1})\n",
    "                res = e_k * b_i\n",
    "                dense_col = jnp.zeros(self.dim)\n",
    "                for bin_key, val in res.items():\n",
    "                    dense_col = dense_col.at[bin_key].set(val)\n",
    "                cols.append(dense_col)\n",
    "            M = jnp.stack(cols, axis=1)\n",
    "            matrices.append(M)\n",
    "        self.basis_matrices = jnp.stack(matrices)\n",
    "\n",
    "    def __hash__(self): return hash((self.p, self.q, self.r))\n",
    "    def __eq__(self, o): return (self.p, self.q, self.r) == (o.p, o.q, o.r)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PHYSICS KERNEL (Unchanged)\n",
    "# ==============================================================================\n",
    "IDX_P = 0\n",
    "class PhysParams(NamedTuple):\n",
    "    c: float\n",
    "    epsilon: float\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra'])\n",
    "def geometric_constitutive_law(u_coeffs, grads_list: List, lap_coeffs, params: PhysParams, algebra: MatrixAlgebra):\n",
    "    rate_coeffs = jnp.zeros_like(u_coeffs)\n",
    "    for i, grad_coeffs in enumerate(grads_list):\n",
    "        if i >= len(algebra.basis_matrices): break\n",
    "        M_i = algebra.basis_matrices[i]\n",
    "        term = jnp.einsum('kj,...j->...k', M_i, grad_coeffs)\n",
    "        rate_coeffs = rate_coeffs - params.c * term\n",
    "    rate_coeffs = rate_coeffs + params.epsilon * lap_coeffs\n",
    "    return rate_coeffs\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. UPDATED INTEGRATOR (Uses Manifold)\n",
    "# ==============================================================================\n",
    "\n",
    "# Now 'manifold' replaces 'dx' and 'ndim'\n",
    "@functools.partial(jit, static_argnames=['model_fn', 'algebra', 'manifold'])\n",
    "def maccormack_step(u, dt, params: PhysParams, model_fn: Callable, algebra: MatrixAlgebra, manifold: Manifold):\n",
    "    \n",
    "    # 1. Geometry (Delegated to Manifold)\n",
    "    grads_fwd, grads_bwd, lap = manifold.gradients(u)\n",
    "    \n",
    "    # 2. Predictor\n",
    "    k1 = model_fn(u, grads_fwd, lap, params, algebra)\n",
    "    u_pred = u + k1 * dt\n",
    "    \n",
    "    # 3. Corrector (Recalculate on predicted state)\n",
    "    _, grads_bwd_pred, lap_pred = manifold.gradients(u_pred)\n",
    "    k2 = model_fn(u_pred, grads_bwd_pred, lap_pred, params, algebra)\n",
    "    \n",
    "    # 4. Average\n",
    "    u_next = 0.5 * (u + u_pred + k2 * dt)\n",
    "    \n",
    "    # 5. Boundaries (Delegated to Manifold)\n",
    "    u_next = manifold.enforce_boundaries(u_next)\n",
    "    \n",
    "    return u_next\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. SIMULATION RUNNER (Abstracted)\n",
    "# ==============================================================================\n",
    "\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "DURATION_STEPS = 1200 \n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold'])\n",
    "def run_simulation(params_dict, epsilon, algebra: MatrixAlgebra, manifold: Manifold):\n",
    "    # Retrieve Coordinates from Manifold\n",
    "    X, Y = manifold.coordinates\n",
    "    \n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    \n",
    "    phys_params = PhysParams(c=343.0, epsilon=epsilon)\n",
    "    x0, y0 = params_dict['pos'][0], params_dict['pos'][1]\n",
    "    vx, vy = params_dict['vel'][0], params_dict['vel'][1]\n",
    "    blob_width = 0.5 + epsilon * 2.0\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_curr = carry\n",
    "        \n",
    "        # Call step with Manifold\n",
    "        u_next = maccormack_step(\n",
    "            u_curr, DT, phys_params, \n",
    "            geometric_constitutive_law, \n",
    "            algebra, \n",
    "            manifold # <--- The abstraction!\n",
    "        )\n",
    "        \n",
    "        current_time = step_idx * DT\n",
    "        pos_x = x0 + vx * current_time\n",
    "        pos_y = y0 + vy * current_time\n",
    "        dist_sq = (X - pos_x)**2 + (Y - pos_y)**2\n",
    "        source = jnp.exp(-dist_sq / (2 * blob_width**2)) * jnp.exp(-(step_idx - 50)**2 / (2 * 20.0**2)) * 100.0 * DT\n",
    "        \n",
    "        u_next = u_next.at[..., IDX_P].add(source)\n",
    "        return u_next, u_next[..., IDX_P]\n",
    "\n",
    "    final_u, history_p = lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))\n",
    "    return history_p\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "def solve():\n",
    "    # 1. Define Objects\n",
    "    algebra = MatrixAlgebra(2, 0)\n",
    "    \n",
    "    # WE CHOOSE THE MANIFOLD HERE\n",
    "    # Change to CartesianTorus(GRID_SIZE, DX) to see wrapping effects!\n",
    "    manifold = CartesianBox(GRID_SIZE, DX) \n",
    "    \n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0])}\n",
    "    SENSORS_RC = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "\n",
    "    print(f\"--- Generating Ground Truth ({manifold.__class__.__name__}) ---\")\n",
    "    true_history = run_simulation(TRUE_PARAMS, epsilon=0.0, algebra=algebra, manifold=manifold)\n",
    "    observed_data = true_history[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "\n",
    "    def loss_fn(est_params, epsilon):\n",
    "        sim_hist = run_simulation(est_params, epsilon, algebra=algebra, manifold=manifold)\n",
    "        sim_data = sim_hist[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "        \n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (observed_data - jnp.mean(observed_data, 0)) / (jnp.std(observed_data, 0) + safe_eps)\n",
    "        \n",
    "        corr = jnp.mean(sim_norm * obs_norm)\n",
    "        pos = est_params['pos']\n",
    "        # Boundary penalty should probably check Manifold bounds, \n",
    "        # but simplistic global bounds are fine for now.\n",
    "        bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "        return (1.0 - corr) + bounds\n",
    "\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0])}\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {'pos': optax.adam(0.1), 'vel': optax.adam(5.0)},\n",
    "            {'pos': 'pos', 'vel': 'vel'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    print(f\"\\n--- Starting Search ---\")\n",
    "    for stage, eps in enumerate([2.0, 0.5, 0.0]):\n",
    "        print(f\"\\n>>> ENTERING STAGE {stage} (Slack Epsilon = {eps}) <<<\")\n",
    "        for i in range(100): \n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            if i % 10 == 0:\n",
    "                p, v = guess['pos'], guess['vel']\n",
    "                print(f\"   Iter {i}: Loss {loss:.5f} | Pos=[{p[0]:.2f}, {p[1]:.2f}] Vel=[{v[0]:.2f}, {v[1]:.2f}]\")\n",
    "\n",
    "    print(f\"\\n--- FINAL RESULT ---\")\n",
    "    print(f\"Estimated: Pos={guess['pos']} Vel={guess['vel']}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932fc1c6-1c1f-4f3a-a5ca-4017f03d3865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth (Universal PDE Engine) ---\n",
      "\n",
      "--- Starting Search ---\n",
      "\n",
      ">>> ENTERING STAGE 0 (Physics: Advection + Diffusion=2.0) <<<\n",
      "   Iter 0: Loss 0.47631 | Pos=[4.90, 5.10] Vel=[-5.00, 5.00]\n",
      "   Iter 10: Loss 0.08123 | Pos=[3.90, 6.10] Vel=[-55.16, 55.17]\n",
      "   Iter 20: Loss 0.02477 | Pos=[3.24, 6.81] Vel=[-86.87, 89.53]\n",
      "   Iter 30: Loss 0.01545 | Pos=[3.41, 6.73] Vel=[-77.00, 84.42]\n",
      "   Iter 40: Loss 0.00603 | Pos=[3.65, 6.46] Vel=[-62.64, 69.30]\n",
      "   Iter 50: Loss 0.00391 | Pos=[3.53, 6.50] Vel=[-65.38, 68.82]\n",
      "   Iter 60: Loss 0.00352 | Pos=[3.45, 6.61] Vel=[-66.34, 71.44]\n",
      "   Iter 70: Loss 0.00268 | Pos=[3.50, 6.59] Vel=[-60.04, 67.43]\n",
      "   Iter 80: Loss 0.00260 | Pos=[3.48, 6.58] Vel=[-57.09, 63.80]\n",
      "   Iter 90: Loss 0.00241 | Pos=[3.44, 6.61] Vel=[-55.17, 62.11]\n",
      "\n",
      ">>> ENTERING STAGE 1 (Physics: Advection + Diffusion=0.5) <<<\n",
      "   Iter 0: Loss 0.00190 | Pos=[3.44, 6.62] Vel=[-51.05, 59.28]\n",
      "   Iter 10: Loss 0.00179 | Pos=[3.43, 6.63] Vel=[-47.65, 56.27]\n",
      "   Iter 20: Loss 0.00167 | Pos=[3.41, 6.64] Vel=[-44.68, 53.71]\n",
      "   Iter 30: Loss 0.00156 | Pos=[3.40, 6.66] Vel=[-41.19, 50.95]\n",
      "   Iter 40: Loss 0.00145 | Pos=[3.38, 6.67] Vel=[-37.96, 48.18]\n",
      "   Iter 50: Loss 0.00134 | Pos=[3.36, 6.68] Vel=[-34.71, 45.46]\n",
      "   Iter 60: Loss 0.00125 | Pos=[3.35, 6.70] Vel=[-31.41, 42.71]\n",
      "   Iter 70: Loss 0.00115 | Pos=[3.33, 6.71] Vel=[-28.21, 40.00]\n",
      "   Iter 80: Loss 0.00106 | Pos=[3.31, 6.72] Vel=[-25.01, 37.31]\n",
      "   Iter 90: Loss 0.00098 | Pos=[3.30, 6.74] Vel=[-21.88, 34.65]\n",
      "\n",
      ">>> ENTERING STAGE 2 (Physics: Advection + Diffusion=0.0) <<<\n",
      "   Iter 0: Loss 0.00084 | Pos=[3.28, 6.75] Vel=[-18.80, 32.04]\n",
      "   Iter 10: Loss 0.00077 | Pos=[3.27, 6.76] Vel=[-15.71, 29.52]\n",
      "   Iter 20: Loss 0.00071 | Pos=[3.26, 6.77] Vel=[-12.90, 27.09]\n",
      "   Iter 30: Loss 0.00065 | Pos=[3.24, 6.78] Vel=[-10.09, 24.71]\n",
      "   Iter 40: Loss 0.00060 | Pos=[3.23, 6.80] Vel=[-7.39, 22.42]\n",
      "   Iter 50: Loss 0.00055 | Pos=[3.22, 6.81] Vel=[-4.78, 20.18]\n",
      "   Iter 60: Loss 0.00050 | Pos=[3.21, 6.82] Vel=[-2.25, 18.02]\n",
      "   Iter 70: Loss 0.00046 | Pos=[3.19, 6.83] Vel=[0.19, 15.93]\n",
      "   Iter 80: Loss 0.00042 | Pos=[3.18, 6.84] Vel=[2.54, 13.91]\n",
      "   Iter 90: Loss 0.00039 | Pos=[3.17, 6.85] Vel=[4.79, 11.96]\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Estimated: Pos=[3.1617506 6.853782 ] Vel=[ 6.739715 10.275469]\n",
      "True     : Pos=[3. 7.] Vel=[ 40. -20.]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "from typing import NamedTuple, List, Callable\n",
    "import optax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CORE MATH: MATRIX ALGEBRA & MANIFOLD\n",
    "# ==============================================================================\n",
    "# (Same robust implementations as before)\n",
    "\n",
    "class MatrixAlgebra:\n",
    "    def __init__(self, p, q, r=0):\n",
    "        self.p, self.q, self.r = p, q, r\n",
    "        self.alg = Algebra(p, q, r)\n",
    "        self.dim = len(self.alg)\n",
    "        self.basis_names = [f'e{i+1}' for i in range(p + q + r)]\n",
    "        matrices = []\n",
    "        for name in self.basis_names:\n",
    "            e_k = self.alg.blades[name]\n",
    "            cols = []\n",
    "            for i in range(self.dim):\n",
    "                b_i = self.alg.multivector({i: 1})\n",
    "                res = e_k * b_i\n",
    "                dense_col = jnp.zeros(self.dim)\n",
    "                for bin_key, val in res.items():\n",
    "                    dense_col = dense_col.at[bin_key].set(val)\n",
    "                cols.append(dense_col)\n",
    "            M = jnp.stack(cols, axis=1)\n",
    "            matrices.append(M)\n",
    "        self.basis_matrices = jnp.stack(matrices)\n",
    "    def __hash__(self): return hash((self.p, self.q, self.r))\n",
    "    def __eq__(self, o): return (self.p, self.q, self.r) == (o.p, o.q, o.r)\n",
    "\n",
    "class CartesianBox:\n",
    "    def __init__(self, size, dx):\n",
    "        self.size = size\n",
    "        self.dx = dx\n",
    "        xs = jnp.linspace(0, size*dx, size)\n",
    "        ys = jnp.linspace(0, size*dx, size)\n",
    "        self.X, self.Y = jnp.meshgrid(xs, ys, indexing='xy')\n",
    "        \n",
    "    def __hash__(self): return hash((self.size, self.dx))\n",
    "    def __eq__(self, o): return (self.size, self.dx) == (o.size, o.dx)\n",
    "\n",
    "    @property\n",
    "    def coordinates(self): return (self.X, self.Y)\n",
    "\n",
    "    def gradients(self, u):\n",
    "        u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "        u_center = u_pad[1:-1, 1:-1]\n",
    "        dx = self.dx\n",
    "        \n",
    "        # Forward\n",
    "        dx_fwd = (u_pad[1:-1, 2:] - u_center) / dx\n",
    "        dy_fwd = (u_pad[2:, 1:-1] - u_center) / dx\n",
    "        # Backward\n",
    "        dx_bwd = (u_center - u_pad[1:-1, 0:-2]) / dx\n",
    "        dy_bwd = (u_center - u_pad[0:-2, 1:-1]) / dx\n",
    "        # Laplacian\n",
    "        lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + \\\n",
    "               u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_center) / (dx**2)\n",
    "               \n",
    "        return ([dx_fwd, dy_fwd], [dx_bwd, dy_bwd], lap)\n",
    "\n",
    "    def enforce_boundaries(self, u):\n",
    "        u = u.at[0, :, :].set(0); u = u.at[-1, :, :].set(0)\n",
    "        u = u.at[:, 0, :].set(0); u = u.at[:, -1, :].set(0)\n",
    "        return u\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THE OPERATOR ABSTRACTION (Lifting the Terms)\n",
    "# ==============================================================================\n",
    "\n",
    "class Operator:\n",
    "    \"\"\" Base class for a differential physics term \"\"\"\n",
    "    def __hash__(self): raise NotImplementedError\n",
    "    def __eq__(self, o): raise NotImplementedError\n",
    "    \n",
    "    def apply(self, u, grads, lap, algebra):\n",
    "        \"\"\" Returns the rate of change d(Psi)/dt contributed by this term \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GeometricAdvection(Operator):\n",
    "    \"\"\"\n",
    "    First Order: dPsi/dt = -c * (Geometric_Gradient * Psi)\n",
    "    Unifies: Acoustics, Maxwell, Dirac\n",
    "    \"\"\"\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "        \n",
    "    def __hash__(self): return hash(('advection', self.c))\n",
    "    def __eq__(self, o): return isinstance(o, GeometricAdvection) and self.c == o.c\n",
    "    \n",
    "    def apply(self, u, grads, lap, algebra):\n",
    "        rate = jnp.zeros_like(u)\n",
    "        # Sum over dimensions: -c * (e_i * d_i_u)\n",
    "        for i, grad_field in enumerate(grads):\n",
    "            if i >= len(algebra.basis_matrices): break\n",
    "            M_i = algebra.basis_matrices[i]\n",
    "            # Matrix-Vector multiply (M_i @ grad)\n",
    "            term = jnp.einsum('kj,...j->...k', M_i, grad_field)\n",
    "            rate = rate - self.c * term\n",
    "        return rate\n",
    "\n",
    "class GeometricDiffusion(Operator):\n",
    "    \"\"\"\n",
    "    Second Order: dPsi/dt = epsilon * Laplacian(Psi)\n",
    "    Unifies: Heat, Viscosity, Schrdinger Kinetic Term\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def __hash__(self): return hash(('diffusion', self.epsilon))\n",
    "    def __eq__(self, o): return isinstance(o, GeometricDiffusion) and self.epsilon == o.epsilon\n",
    "\n",
    "    def apply(self, u, grads, lap, algebra):\n",
    "        # Scalar multiplication of the Laplacian field\n",
    "        return self.epsilon * lap\n",
    "\n",
    "class LinearPotential(Operator):\n",
    "    \"\"\"\n",
    "    Zero Order: dPsi/dt = -V * Psi\n",
    "    Unifies: Mass, Damping, Potential Wells\n",
    "    \"\"\"\n",
    "    def __init__(self, potential_val):\n",
    "        self.V = potential_val\n",
    "        \n",
    "    def __hash__(self): return hash(('potential', self.V))\n",
    "    def __eq__(self, o): return isinstance(o, LinearPotential) and self.V == o.V\n",
    "\n",
    "    def apply(self, u, grads, lap, algebra):\n",
    "        return -self.V * u\n",
    "\n",
    "class CompositePDE:\n",
    "    \"\"\" The Hamiltonian: A sum of operators \"\"\"\n",
    "    def __init__(self, operators: List[Operator]):\n",
    "        self.operators = tuple(operators) # Tuple is hashable\n",
    "        \n",
    "    def __hash__(self): return hash(self.operators)\n",
    "    def __eq__(self, o): return self.operators == o.operators\n",
    "    \n",
    "    def __call__(self, u, grads, lap, algebra):\n",
    "        total_rate = jnp.zeros_like(u)\n",
    "        for op in self.operators:\n",
    "            total_rate = total_rate + op.apply(u, grads, lap, algebra)\n",
    "        return total_rate\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. THE UNIVERSAL INTEGRATOR\n",
    "# ==============================================================================\n",
    "\n",
    "@functools.partial(jit, static_argnames=['pde', 'algebra', 'manifold'])\n",
    "def maccormack_step(u, dt, pde: CompositePDE, algebra: MatrixAlgebra, manifold: CartesianBox):\n",
    "    # 1. Geometry\n",
    "    grads_fwd, grads_bwd, lap = manifold.gradients(u)\n",
    "    \n",
    "    # 2. Predictor (Using PDE object)\n",
    "    k1 = pde(u, grads_fwd, lap, algebra)\n",
    "    u_pred = u + k1 * dt\n",
    "    \n",
    "    # 3. Corrector\n",
    "    _, grads_bwd_pred, lap_pred = manifold.gradients(u_pred)\n",
    "    k2 = pde(u_pred, grads_bwd_pred, lap_pred, algebra)\n",
    "    \n",
    "    # 4. Update\n",
    "    u_next = 0.5 * (u + u_pred + k2 * dt)\n",
    "    u_next = manifold.enforce_boundaries(u_next)\n",
    "    return u_next\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. SIMULATION RUNNER\n",
    "# ==============================================================================\n",
    "\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "DURATION_STEPS = 1200 \n",
    "IDX_P = 0\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold', 'pde'])\n",
    "def run_simulation(params_dict, pde: CompositePDE, algebra: MatrixAlgebra, manifold: CartesianBox):\n",
    "    X, Y = manifold.coordinates\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    \n",
    "    x0, y0 = params_dict['pos'][0], params_dict['pos'][1]\n",
    "    vx, vy = params_dict['vel'][0], params_dict['vel'][1]\n",
    "    \n",
    "    # Retrieve 'epsilon' from the PDE to size the source blob?\n",
    "    # For now, we hardcode blob width or inspect the diffusion term if needed.\n",
    "    # Let's assume generic blob.\n",
    "    blob_width = 1.5 \n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_curr = carry\n",
    "        \n",
    "        # Call Integrator with PDE\n",
    "        u_next = maccormack_step(u_curr, DT, pde, algebra, manifold)\n",
    "        \n",
    "        current_time = step_idx * DT\n",
    "        pos_x = x0 + vx * current_time\n",
    "        pos_y = y0 + vy * current_time\n",
    "        dist_sq = (X - pos_x)**2 + (Y - pos_y)**2\n",
    "        source = jnp.exp(-dist_sq / (2 * blob_width**2)) * jnp.exp(-(step_idx - 50)**2 / (2 * 20.0**2)) * 100.0 * DT\n",
    "        \n",
    "        u_next = u_next.at[..., IDX_P].add(source)\n",
    "        return u_next, u_next[..., IDX_P]\n",
    "\n",
    "    final_u, history_p = lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))\n",
    "    return history_p\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "def solve():\n",
    "    # 1. Define World\n",
    "    algebra = MatrixAlgebra(2, 0)\n",
    "    manifold = CartesianBox(GRID_SIZE, DX)\n",
    "    \n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0])}\n",
    "    SENSORS_RC = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "\n",
    "    # 2. Define Physics as LEGO BLOCKS (Target Physics)\n",
    "    # Target: Pure Acoustics (Epsilon=0)\n",
    "    target_physics = CompositePDE([\n",
    "        GeometricAdvection(c=343.0),\n",
    "        GeometricDiffusion(epsilon=0.0) \n",
    "    ])\n",
    "\n",
    "    print(f\"--- Generating Ground Truth (Universal PDE Engine) ---\")\n",
    "    true_history = run_simulation(TRUE_PARAMS, target_physics, algebra, manifold)\n",
    "    observed_data = true_history[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "\n",
    "    # 3. Define Loss Function\n",
    "    # Note: We must construct a NEW PDE object for each epsilon stage!\n",
    "    def loss_fn(est_params, current_epsilon):\n",
    "        # Dynamic Physics Construction!\n",
    "        current_physics = CompositePDE([\n",
    "            GeometricAdvection(c=343.0),\n",
    "            GeometricDiffusion(epsilon=current_epsilon)\n",
    "        ])\n",
    "        \n",
    "        sim_hist = run_simulation(est_params, current_physics, algebra, manifold)\n",
    "        sim_data = sim_hist[:, SENSORS_RC[:,0], SENSORS_RC[:,1]]\n",
    "        \n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (observed_data - jnp.mean(observed_data, 0)) / (jnp.std(observed_data, 0) + safe_eps)\n",
    "        corr = jnp.mean(sim_norm * obs_norm)\n",
    "        \n",
    "        pos = est_params['pos']\n",
    "        bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "        return (1.0 - corr) + bounds\n",
    "\n",
    "    # 4. Optimization Loop\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0])}\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {'pos': optax.adam(0.1), 'vel': optax.adam(5.0)},\n",
    "            {'pos': 'pos', 'vel': 'vel'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    print(f\"\\n--- Starting Search ---\")\n",
    "    # Annealing Schedule: Reduce epsilon (Diffusion term) over time\n",
    "    for stage, eps in enumerate([2.0, 0.5, 0.0]):\n",
    "        print(f\"\\n>>> ENTERING STAGE {stage} (Physics: Advection + Diffusion={eps}) <<<\")\n",
    "        for i in range(100): \n",
    "            # Note: We pass 'eps' to loss_fn, which constructs the PDE internally\n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            if i % 10 == 0:\n",
    "                p, v = guess['pos'], guess['vel']\n",
    "                print(f\"   Iter {i}: Loss {loss:.5f} | Pos=[{p[0]:.2f}, {p[1]:.2f}] Vel=[{v[0]:.2f}, {v[1]:.2f}]\")\n",
    "\n",
    "    print(f\"\\n--- FINAL RESULT ---\")\n",
    "    print(f\"Estimated: Pos={guess['pos']} Vel={guess['vel']}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc87e2e-7b33-4ea1-a46f-04fa6688382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth ---\n",
      "\n",
      "--- Discovering Physics ---\n",
      ">>> Epsilon 2.0\n",
      "Iter 0: L=0.4140 | c=299.0 | V=0.10 | Pos=[4.9000006 5.0999994]\n",
      "Iter 10: L=0.1076 | c=308.0 | V=1.12 | Pos=[3.9292595 6.0769677]\n",
      "Iter 20: L=0.0642 | c=318.8 | V=2.20 | Pos=[3.5451179 6.5610857]\n",
      "Iter 30: L=0.0189 | c=329.3 | V=3.13 | Pos=[3.7362127 6.400748 ]\n",
      "Iter 40: L=0.0087 | c=336.2 | V=3.61 | Pos=[3.596058 6.427496]\n",
      ">>> Epsilon 1.0\n",
      "Iter 0: L=0.0040 | c=340.4 | V=3.73 | Pos=[3.4598937 6.5909076]\n",
      "Iter 10: L=0.0026 | c=343.2 | V=3.66 | Pos=[3.5011408 6.5931168]\n",
      "Iter 20: L=0.0024 | c=344.1 | V=3.45 | Pos=[3.4383194 6.6044083]\n",
      "Iter 30: L=0.0022 | c=344.1 | V=3.16 | Pos=[3.4145033 6.6372914]\n",
      "Iter 40: L=0.0020 | c=343.8 | V=2.86 | Pos=[3.4138277 6.6435943]\n",
      ">>> Epsilon 0.0\n",
      "Iter 0: L=0.0016 | c=343.5 | V=2.55 | Pos=[3.382498  6.6572013]\n",
      "Iter 10: L=0.0014 | c=343.2 | V=2.30 | Pos=[3.3764687 6.671409 ]\n",
      "Iter 20: L=0.0013 | c=343.1 | V=2.09 | Pos=[3.352902  6.6860533]\n",
      "Iter 30: L=0.0012 | c=343.0 | V=1.92 | Pos=[3.3352036 6.700586 ]\n",
      "Iter 40: L=0.0010 | c=343.1 | V=1.76 | Pos=[3.3157027 6.717162 ]\n",
      "\n",
      "--- FINAL DISCOVERY ---\n",
      "True: c=343.0, V=0.5\n",
      "Est : c=343.1, V=1.63\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "import optax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "\n",
    "# ... [Include MatrixAlgebra, CartesianBox, get_gradients from previous step] ...\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. THE UNIVERSAL OPERATORS (With Learnable Parameters)\n",
    "# ==============================================================================\n",
    "\n",
    "# We modify the PDE call to accept a parameter dictionary directly\n",
    "# instead of having fixed classes.\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra'])\n",
    "def universal_pde_kernel(u, grads, lap, params_dict, algebra):\n",
    "    \"\"\"\n",
    "    The Hamiltonian: H(u) = -c(Advection) + epsilon(Diffusion) - V(Potential)\n",
    "    All coefficients (c, epsilon, V) are now passed dynamically.\n",
    "    \"\"\"\n",
    "    rate = jnp.zeros_like(u)\n",
    "    \n",
    "    # 1. Geometric Advection (Wave Speed c)\n",
    "    # Term: -c * sum(e_i * d_i u)\n",
    "    c = params_dict['c']\n",
    "    for i, grad_field in enumerate(grads):\n",
    "        if i >= len(algebra.basis_matrices): break\n",
    "        M_i = algebra.basis_matrices[i]\n",
    "        term = jnp.einsum('kj,...j->...k', M_i, grad_field)\n",
    "        rate = rate - c * term\n",
    "\n",
    "    # 2. Geometric Diffusion (Viscosity epsilon)\n",
    "    # Term: +epsilon * Laplacian(u)\n",
    "    # Note: We usually fix epsilon for annealing, but we COULD learn it.\n",
    "    # Here we treat it as a hyperparameter passed in params_dict.\n",
    "    eps = params_dict['epsilon']\n",
    "    rate = rate + eps * lap\n",
    "    \n",
    "    # 3. Linear Potential (Damping/Mass V)\n",
    "    # Term: -V * u\n",
    "    V = params_dict['V']\n",
    "    rate = rate - V * u\n",
    "    \n",
    "    return rate\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THE SIMULATION (Accepts Physics Params)\n",
    "# ==============================================================================\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold'])\n",
    "def run_simulation(learnable_params, hyper_params, algebra, manifold):\n",
    "    \"\"\"\n",
    "    learnable_params: {pos, vel, c, V} -> The things we want to find.\n",
    "    hyper_params: {epsilon} -> The solver controls.\n",
    "    \"\"\"\n",
    "    X, Y = manifold.coordinates\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    \n",
    "    # Unpack Logic\n",
    "    x0, y0 = learnable_params['pos']\n",
    "    vx, vy = learnable_params['vel']\n",
    "    \n",
    "    # Combine all params for the kernel\n",
    "    # We detach epsilon (it's a control variable, not a physical truth we are searching for yet)\n",
    "    pde_params = {\n",
    "        'c': learnable_params['c'], \n",
    "        'V': learnable_params['V'],\n",
    "        'epsilon': hyper_params['epsilon']\n",
    "    }\n",
    "    \n",
    "    blob_width = 1.5\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_curr = carry\n",
    "        \n",
    "        # 1. Geometry\n",
    "        grads_fwd, grads_bwd, lap = manifold.gradients(u_curr)\n",
    "        \n",
    "        # 2. Predictor\n",
    "        k1 = universal_pde_kernel(u_curr, grads_fwd, lap, pde_params, algebra)\n",
    "        u_pred = u_curr + k1 * DT\n",
    "        \n",
    "        # 3. Corrector\n",
    "        _, grads_bwd_pred, lap_pred = manifold.gradients(u_pred)\n",
    "        k2 = universal_pde_kernel(u_pred, grads_bwd_pred, lap_pred, pde_params, algebra)\n",
    "        \n",
    "        u_next = 0.5 * (u_curr + u_pred + k2 * DT)\n",
    "        u_next = manifold.enforce_boundaries(u_next)\n",
    "        \n",
    "        # 4. Source\n",
    "        t = step_idx * DT\n",
    "        pos_x = x0 + vx * t\n",
    "        pos_y = y0 + vy * t\n",
    "        dist_sq = (X - pos_x)**2 + (Y - pos_y)**2\n",
    "        source = jnp.exp(-dist_sq / (2 * blob_width**2)) * jnp.exp(-(step_idx - 50)**2 / (2 * 20.0**2)) * 100.0 * DT\n",
    "        \n",
    "        u_next = u_next.at[..., 0].add(source)\n",
    "        return u_next, u_next[..., 0]\n",
    "\n",
    "    final_u, history_p = lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))\n",
    "    return history_p\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. EXECUTION: LEARNING PHYSICS FROM SCRATCH\n",
    "# ==============================================================================\n",
    "\n",
    "def solve_universal():\n",
    "    algebra = MatrixAlgebra(2, 0)\n",
    "    manifold = CartesianBox(GRID_SIZE, DX)\n",
    "    \n",
    "    # --- GROUND TRUTH ---\n",
    "    # We simulate a world with specific physics:\n",
    "    # Speed of Sound = 343 m/s\n",
    "    # Damping (V) = 0.5 (Air resistance?)\n",
    "    TRUE_PARAMS = {\n",
    "        'pos': jnp.array([3.0, 7.0]), \n",
    "        'vel': jnp.array([40.0, -20.0]),\n",
    "        'c': 343.0,\n",
    "        'V': 0.5\n",
    "    }\n",
    "    \n",
    "    print(\"--- Generating Ground Truth ---\")\n",
    "    # Generate data with epsilon=0 (Real Physics)\n",
    "    true_hist = run_simulation(TRUE_PARAMS, {'epsilon': 0.0}, algebra, manifold)\n",
    "    SENSORS = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "    obs_data = true_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "\n",
    "    # --- THE BLIND SOLVER ---\n",
    "    # We guess EVERYTHING.\n",
    "    # \"I don't know where it is, how fast it's moving, or what the speed of sound is.\"\n",
    "    guess = {\n",
    "        'pos': jnp.array([5.0, 5.0]), \n",
    "        'vel': jnp.array([0.0, 0.0]),\n",
    "        'c': 300.0,  # Wrong guess (Standard air is 343)\n",
    "        'V': 0.0     # Wrong guess (Assume vacuum)\n",
    "    }\n",
    "\n",
    "    # Complex Optimizer Strategy\n",
    "    # We need different learning rates for different physical units!\n",
    "    # c (~300) needs large updates? No, c is sensitive. Small updates relative to mag.\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {\n",
    "                'pos': optax.adam(0.1), \n",
    "                'vel': optax.adam(5.0),\n",
    "                'c':   optax.adam(1.0), # Learn speed of sound\n",
    "                'V':   optax.adam(0.1)  # Learn damping\n",
    "            },\n",
    "            {'pos':'pos', 'vel':'vel', 'c':'c', 'V':'V'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    def loss_fn(params, eps):\n",
    "        sim_hist = run_simulation(params, {'epsilon': eps}, algebra, manifold)\n",
    "        sim_data = sim_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "        \n",
    "        # Normalize (Correlation Loss is safer for 'c' estimation than MSE)\n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (obs_data - jnp.mean(obs_data, 0)) / (jnp.std(obs_data, 0) + safe_eps)\n",
    "        return 1.0 - jnp.mean(sim_norm * obs_norm)\n",
    "\n",
    "    print(\"\\n--- Discovering Physics ---\")\n",
    "    # Anneal Epsilon to help find 'c' and 'pos' simultaneously\n",
    "    for eps in [2.0, 1.0, 0.0]:\n",
    "        print(f\">>> Epsilon {eps}\")\n",
    "        for i in range(50):\n",
    "            l, g = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(g, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"Iter {i}: L={l:.4f} | c={guess['c']:.1f} | V={guess['V']:.2f} | Pos={guess['pos']}\")\n",
    "\n",
    "    print(\"\\n--- FINAL DISCOVERY ---\")\n",
    "    print(f\"True: c={TRUE_PARAMS['c']}, V={TRUE_PARAMS['V']}\")\n",
    "    print(f\"Est : c={guess['c']:.1f}, V={guess['V']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solve_universal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba39dad8-2bbc-4dda-b537-82f53073ef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Ground Truth ---\n",
      "\n",
      "--- Starting Controlled Search ---\n",
      "Goal: Loss < 0.0005 OR Iter > 100\n",
      "\n",
      ">>> STAGE 0 (Epsilon=2.0) <<<\n",
      "   Iter 0: L=0.4140 | Grad=0.1996 | c=299.0 | Pos=[4.9000006 5.0999994]\n",
      "   Iter 10: L=0.1076 | Grad=0.0792 | c=308.0 | Pos=[3.9292595 6.0769677]\n",
      "   Iter 20: L=0.0642 | Grad=0.0875 | c=318.8 | Pos=[3.5451179 6.5610857]\n",
      "   Iter 30: L=0.0189 | Grad=0.0244 | c=329.3 | Pos=[3.7362123 6.400748 ]\n",
      "   Iter 40: L=0.0087 | Grad=0.0310 | c=336.2 | Pos=[3.5960577 6.4274964]\n",
      "   Iter 50: L=0.0044 | Grad=0.0163 | c=340.4 | Pos=[3.4597843 6.590959 ]\n",
      "   Iter 60: L=0.0029 | Grad=0.0076 | c=343.2 | Pos=[3.498338 6.594799]\n",
      "   Iter 70: L=0.0027 | Grad=0.0044 | c=344.2 | Pos=[3.4360435 6.606053 ]\n",
      "   Iter 80: L=0.0025 | Grad=0.0027 | c=344.3 | Pos=[3.4100184 6.6401525]\n",
      "   [SKIP] Converged (Grad Norm 0.000849 < 0.001)\n",
      "\n",
      ">>> STAGE 1 (Epsilon=0.5) <<<\n",
      "   [SKIP] Converged (Grad Norm 0.000988 < 0.001)\n",
      "\n",
      ">>> STAGE 2 (Epsilon=0.0) <<<\n",
      "   [SKIP] Converged (Grad Norm 0.000967 < 0.001)\n",
      "\n",
      "--- FINAL DISCOVERY ---\n",
      "True: c=343.0, V=0.5\n",
      "Est : c=344.2, V=2.85\n",
      "Estimated: Pos=[3.4162002 6.6445756] Vel=[-47.815582  57.555668]\n",
      "True     : Pos=[3. 7.] Vel=[ 40. -20.]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "import optax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "from typing import NamedTuple, List, Dict\n",
    "\n",
    "# ... [Keep MatrixAlgebra, CartesianBox, Operators, maccormack_step from previous] ...\n",
    "# (Assuming previous definitions of MatrixAlgebra, CartesianBox, Operators are present)\n",
    "# For brevity, I will re-include the minimal necessary parts or assume they are imported.\n",
    "# Below is the FULL updated \"Control Logic\" section.\n",
    "\n",
    "# ... [Paste previous MatrixAlgebra / CartesianBox / Universal PDE Kernel classes here] ...\n",
    "# ... [For a standalone run, copy classes from the previous 'universal' script] ...\n",
    "# ... [I will include them for completeness so this block runs standalone] ...\n",
    "\n",
    "# --- RE-DEFINING ESSENTIALS FOR STANDALONE EXECUTION ---\n",
    "class MatrixAlgebra:\n",
    "    def __init__(self, p, q, r=0):\n",
    "        self.p, self.q, self.r = p, q, r\n",
    "        self.alg = Algebra(p, q, r)\n",
    "        self.dim = len(self.alg)\n",
    "        self.basis_names = [f'e{i+1}' for i in range(p + q + r)]\n",
    "        matrices = []\n",
    "        for name in self.basis_names:\n",
    "            e_k = self.alg.blades[name]\n",
    "            cols = []\n",
    "            for i in range(self.dim):\n",
    "                b_i = self.alg.multivector({i: 1})\n",
    "                res = e_k * b_i\n",
    "                dense_col = jnp.zeros(self.dim)\n",
    "                for bin_key, val in res.items(): dense_col = dense_col.at[bin_key].set(val)\n",
    "                cols.append(dense_col)\n",
    "            matrices.append(jnp.stack(cols, axis=1))\n",
    "        self.basis_matrices = jnp.stack(matrices)\n",
    "    def __hash__(self): return hash((self.p, self.q, self.r))\n",
    "    def __eq__(self, o): return (self.p, self.q, self.r) == (o.p, o.q, o.r)\n",
    "\n",
    "class CartesianBox:\n",
    "    def __init__(self, size, dx):\n",
    "        self.size, self.dx = size, dx\n",
    "        xs = jnp.linspace(0, size*dx, size)\n",
    "        self.X, self.Y = jnp.meshgrid(xs, xs, indexing='xy')\n",
    "    def __hash__(self): return hash((self.size, self.dx))\n",
    "    def __eq__(self, o): return (self.size, self.dx) == (o.size, o.dx)\n",
    "    @property\n",
    "    def coordinates(self): return (self.X, self.Y)\n",
    "    def gradients(self, u):\n",
    "        u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "        u_c = u_pad[1:-1, 1:-1]; dx = self.dx\n",
    "        dx_f = (u_pad[1:-1, 2:] - u_c)/dx; dy_f = (u_pad[2:, 1:-1] - u_c)/dx\n",
    "        dx_b = (u_c - u_pad[1:-1, 0:-2])/dx; dy_b = (u_c - u_pad[0:-2, 1:-1])/dx\n",
    "        lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_c)/(dx**2)\n",
    "        return ([dx_f, dy_f], [dx_b, dy_b], lap)\n",
    "    def enforce_boundaries(self, u):\n",
    "        u = u.at[0].set(0); u = u.at[-1].set(0); u = u.at[:, 0].set(0); u = u.at[:, -1].set(0)\n",
    "        return u\n",
    "\n",
    "GRID_SIZE, DX, DT, DURATION_STEPS, IDX_P = 100, 0.1, 0.0001, 1200, 0\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra'])\n",
    "def universal_pde_kernel(u, grads, lap, params_dict, algebra):\n",
    "    rate = jnp.zeros_like(u)\n",
    "    # Advection\n",
    "    for i, grad in enumerate(grads):\n",
    "        if i >= len(algebra.basis_matrices): break\n",
    "        rate = rate - params_dict['c'] * jnp.einsum('kj,...j->...k', algebra.basis_matrices[i], grad)\n",
    "    # Diffusion + Potential\n",
    "    rate = rate + params_dict['epsilon'] * lap - params_dict['V'] * u\n",
    "    return rate\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold'])\n",
    "def maccormack_step(u, dt, params, algebra, manifold):\n",
    "    g_f, g_b, lap = manifold.gradients(u)\n",
    "    k1 = universal_pde_kernel(u, g_f, lap, params, algebra)\n",
    "    u_p = u + k1 * dt\n",
    "    _, g_b_p, lap_p = manifold.gradients(u_p)\n",
    "    k2 = universal_pde_kernel(u_p, g_b_p, lap_p, params, algebra)\n",
    "    return manifold.enforce_boundaries(0.5 * (u + u_p + k2 * dt))\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold'])\n",
    "def run_simulation(learn_params, hyper_params, algebra, manifold):\n",
    "    X, Y = manifold.coordinates\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    x0, y0 = learn_params['pos']\n",
    "    vx, vy = learn_params['vel']\n",
    "    pde_params = {'c': learn_params['c'], 'V': learn_params['V'], 'epsilon': hyper_params['epsilon']}\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_next = maccormack_step(carry, DT, pde_params, algebra, manifold)\n",
    "        t = step_idx * DT\n",
    "        src = jnp.exp(-((X-(x0+vx*t))**2 + (Y-(y0+vy*t))**2)/4.5) * jnp.exp(-(step_idx-50)**2/800.0) * 100.0 * DT\n",
    "        u_next = u_next.at[..., 0].add(src)\n",
    "        return u_next, u_next[..., 0]\n",
    "    return lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))[1]\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. CONTROLLED OPTIMIZATION LOGIC\n",
    "# ==============================================================================\n",
    "\n",
    "class SolverConfig(NamedTuple):\n",
    "    target_precision: float # Stop if loss < this\n",
    "    max_iter_per_stage: int # Budget per epsilon stage\n",
    "    min_grad_norm: float    # Stop if gradients vanish (convergence)\n",
    "    epsilon_schedule: List[float]\n",
    "\n",
    "def solve_with_controls(config: SolverConfig):\n",
    "    algebra = MatrixAlgebra(2, 0)\n",
    "    manifold = CartesianBox(GRID_SIZE, DX)\n",
    "    \n",
    "    # --- GROUND TRUTH ---\n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0]), 'c': 343.0, 'V': 0.5}\n",
    "    print(\"--- Generating Ground Truth ---\")\n",
    "    true_hist = run_simulation(TRUE_PARAMS, {'epsilon': 0.0}, algebra, manifold)\n",
    "    SENSORS = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "    obs_data = true_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "\n",
    "    # --- SETUP OPTIMIZER ---\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0]), 'c': 300.0, 'V': 0.0}\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {'pos': optax.adam(0.1), 'vel': optax.adam(5.0), 'c': optax.adam(1.0), 'V': optax.adam(0.1)},\n",
    "            {'pos':'pos', 'vel':'vel', 'c':'c', 'V':'V'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    # Loss Function (Correlation)\n",
    "    def loss_fn(params, eps):\n",
    "        sim_hist = run_simulation(params, {'epsilon': eps}, algebra, manifold)\n",
    "        sim_data = sim_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (obs_data - jnp.mean(obs_data, 0)) / (jnp.std(obs_data, 0) + safe_eps)\n",
    "        # Bounds penalty\n",
    "        pos = params['pos']\n",
    "        bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "        return (1.0 - jnp.mean(sim_norm * obs_norm)) + bounds\n",
    "\n",
    "    print(f\"\\n--- Starting Controlled Search ---\")\n",
    "    print(f\"Goal: Loss < {config.target_precision} OR Iter > {config.max_iter_per_stage}\")\n",
    "    \n",
    "    for stage, eps in enumerate(config.epsilon_schedule):\n",
    "        print(f\"\\n>>> STAGE {stage} (Epsilon={eps}) <<<\")\n",
    "        \n",
    "        for i in range(config.max_iter_per_stage):\n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            \n",
    "            # --- CONTROL LOGIC ---\n",
    "            \n",
    "            # 1. Check Precision (Success)\n",
    "            # We usually only trust low-loss on the final stage (Real Physics)\n",
    "            if loss < config.target_precision and eps == 0.0:\n",
    "                print(f\"   [STOP] Target precision reached at Iter {i}: Loss {loss:.6f}\")\n",
    "                break\n",
    "                \n",
    "            # 2. Check Gradient Norm (Stagnation)\n",
    "            # Flatten gradients to compute global norm\n",
    "            grad_norm = jnp.sqrt(sum(jnp.sum(g**2) for g in jax.tree_util.tree_leaves(grads)))\n",
    "            if grad_norm < config.min_grad_norm:\n",
    "                print(f\"   [SKIP] Converged (Grad Norm {grad_norm:.6f} < {config.min_grad_norm})\")\n",
    "                break\n",
    "            \n",
    "            # Log\n",
    "            if i % 10 == 0:\n",
    "                p, c_est = guess['pos'], guess['c']\n",
    "                print(f\"   Iter {i}: L={loss:.4f} | Grad={grad_norm:.4f} | c={c_est:.1f} | Pos={p}\")\n",
    "        else:\n",
    "            # Python's 'for-else': Runs if loop completed WITHOUT break\n",
    "            print(f\"   [NEXT] Max iterations ({config.max_iter_per_stage}) reached.\")\n",
    "\n",
    "    print(\"\\n--- FINAL DISCOVERY ---\")\n",
    "    print(f\"True: c={TRUE_PARAMS['c']}, V={TRUE_PARAMS['V']}\")\n",
    "    print(f\"Est : c={guess['c']:.1f}, V={guess['V']:.2f}\")\n",
    "    p_final = guess['pos']\n",
    "    v_final = guess['vel']\n",
    "    \n",
    "    print(f\"Estimated: Pos={p_final} Vel={v_final}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define our constraints\n",
    "    config = SolverConfig(\n",
    "        target_precision=0.0005,  # Stop if correlation error < 0.5%\n",
    "        max_iter_per_stage=100,   # Don't waste time on high-epsilon stages\n",
    "        min_grad_norm=0.001,     # Stop if optimization flatlines\n",
    "        epsilon_schedule=[2.0, 0.5, 0.0]\n",
    "    )\n",
    "    solve_with_controls(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129721a-1261-4249-b5af-a331141eb700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e69c56-d194-437b-b9b0-90cd03b5f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Controlled Search ---\n",
      "\n",
      ">>> STAGE 0 (Epsilon=2.0) <<<\n",
      "   Iter 0 (Warmup): L=0.4140 | Grad=0.19956\n",
      "   Iter 10 (Warmup): L=0.1049 | Grad=0.08094\n",
      "   Iter 20: L=0.0611 | Grad=0.08734 | c=318.8 | V=10.92\n",
      "   Iter 30: L=0.0186 | Grad=0.02335 | c=329.3 | V=14.92\n",
      "   Iter 40: L=0.0105 | Grad=0.03067 | c=335.9 | V=15.37\n",
      "   Iter 50: L=0.0064 | Grad=0.01621 | c=339.7 | V=13.31\n",
      "   Iter 60: L=0.0042 | Grad=0.00714 | c=342.4 | V=10.27\n",
      "   Iter 70: L=0.0032 | Grad=0.00462 | c=343.4 | V=6.84\n",
      "   Iter 80: L=0.0025 | Grad=0.00268 | c=343.6 | V=3.69\n",
      "   Iter 90: L=0.0021 | Grad=0.00346 | c=343.7 | V=1.20\n",
      "   Iter 100: L=0.0018 | Grad=0.00093 | c=343.6 | V=-0.58\n",
      "   Iter 110: L=0.0016 | Grad=0.00138 | c=343.7 | V=-1.66\n",
      "   Iter 120: L=0.0015 | Grad=0.00105 | c=343.7 | V=-2.21\n",
      "   Iter 130: L=0.0014 | Grad=0.00092 | c=343.8 | V=-2.40\n",
      "   Iter 140: L=0.0012 | Grad=0.00099 | c=343.8 | V=-2.42\n",
      "\n",
      ">>> STAGE 1 (Epsilon=0.5) <<<\n",
      "   Iter 0 (Warmup): L=0.0010 | Grad=0.00033\n",
      "   Iter 10 (Warmup): L=0.0009 | Grad=0.00104\n",
      "   Iter 20: L=0.0008 | Grad=0.00044 | c=343.5 | V=-1.30\n",
      "   Iter 30: L=0.0007 | Grad=0.00079 | c=343.4 | V=-0.80\n",
      "   Iter 40: L=0.0006 | Grad=0.00053 | c=343.3 | V=-0.48\n",
      "   Iter 50: L=0.0005 | Grad=0.00063 | c=343.3 | V=-0.32\n",
      "   Iter 60: L=0.0005 | Grad=0.00050 | c=343.3 | V=-0.27\n",
      "   Iter 70: L=0.0004 | Grad=0.00051 | c=343.3 | V=-0.27\n",
      "   Iter 80: L=0.0004 | Grad=0.00045 | c=343.3 | V=-0.29\n",
      "   Iter 90: L=0.0004 | Grad=0.00043 | c=343.3 | V=-0.30\n"
     ]
    }
   ],
   "source": [
    "# ... (Previous imports and class definitions remain the same) ...\n",
    "\n",
    "class SolverConfig(NamedTuple):\n",
    "    target_precision: float \n",
    "    max_iter_per_stage: int\n",
    "    min_grad_norm: float\n",
    "    warmup_steps: int      # NEW: Force minimum steps per stage\n",
    "    epsilon_schedule: List[float]\n",
    "\n",
    "def solve_with_controls(config: SolverConfig):\n",
    "    algebra = MatrixAlgebra(2, 0)\n",
    "    manifold = CartesianBox(GRID_SIZE, DX)\n",
    "    \n",
    "    # --- GROUND TRUTH ---\n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0]), 'c': 343.0, 'V': 0.5}\n",
    "    true_hist = run_simulation(TRUE_PARAMS, {'epsilon': 0.0}, algebra, manifold)\n",
    "    SENSORS = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "    obs_data = true_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "\n",
    "    # --- SETUP OPTIMIZER ---\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0]), 'c': 300.0, 'V': 0.0}\n",
    "    \n",
    "    # We maintain the 50x learning rate for Velocity, \n",
    "    # and maybe boost V slightly if it lags?\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {\n",
    "                'pos': optax.adam(0.1), \n",
    "                'vel': optax.adam(5.0), \n",
    "                'c':   optax.adam(1.0), \n",
    "                'V':   optax.adam(0.5)  # Boosted V learning rate slightly\n",
    "            },\n",
    "            {'pos':'pos', 'vel':'vel', 'c':'c', 'V':'V'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    def loss_fn(params, eps):\n",
    "        sim_hist = run_simulation(params, {'epsilon': eps}, algebra, manifold)\n",
    "        sim_data = sim_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (obs_data - jnp.mean(obs_data, 0)) / (jnp.std(obs_data, 0) + safe_eps)\n",
    "        \n",
    "        pos = params['pos']\n",
    "        bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "        return (1.0 - jnp.mean(sim_norm * obs_norm)) + bounds\n",
    "\n",
    "    print(f\"\\n--- Starting Controlled Search ---\")\n",
    "    \n",
    "    for stage, eps in enumerate(config.epsilon_schedule):\n",
    "        print(f\"\\n>>> STAGE {stage} (Epsilon={eps}) <<<\")\n",
    "        \n",
    "        # Reset best loss for this stage\n",
    "        stage_best_loss = 1e9\n",
    "        \n",
    "        for i in range(config.max_iter_per_stage):\n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            guess = optax.apply_updates(guess, updates)\n",
    "            \n",
    "            grad_norm = jnp.sqrt(sum(jnp.sum(g**2) for g in jax.tree_util.tree_leaves(grads)))\n",
    "            \n",
    "            # --- UPDATED CONTROL LOGIC ---\n",
    "            \n",
    "            # 1. Warmup Check: Ignore convergence signals early in the stage\n",
    "            if i < config.warmup_steps:\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"   Iter {i} (Warmup): L={loss:.4f} | Grad={grad_norm:.5f}\")\n",
    "                continue\n",
    "\n",
    "            # 2. Convergence Check\n",
    "            if grad_norm < config.min_grad_norm:\n",
    "                print(f\"   [SKIP] Converged at Iter {i} (Grad {grad_norm:.6f} < {config.min_grad_norm})\")\n",
    "                break\n",
    "                \n",
    "            # 3. Precision Check (Only in final stage)\n",
    "            if loss < config.target_precision and eps == 0.0:\n",
    "                print(f\"   [STOP] Target precision reached: Loss {loss:.6f}\")\n",
    "                break\n",
    "            \n",
    "            # Log\n",
    "            if i % 10 == 0:\n",
    "                p, c_est, v_est = guess['pos'], guess['c'], guess['V']\n",
    "                print(f\"   Iter {i}: L={loss:.4f} | Grad={grad_norm:.5f} | c={c_est:.1f} | V={v_est:.2f}\")\n",
    "\n",
    "    print(\"\\n--- FINAL DISCOVERY ---\")\n",
    "    print(f\"True: c={TRUE_PARAMS['c']}, V={TRUE_PARAMS['V']}\")\n",
    "    print(f\"Est : c={guess['c']:.1f}, V={guess['V']:.2f}\")\n",
    "    p_final = guess['pos']\n",
    "    v_final = guess['vel']\n",
    "    print(f\"Estimated: Pos={p_final} Vel={v_final}\")\n",
    "    print(f\"True     : Pos={TRUE_PARAMS['pos']} Vel={TRUE_PARAMS['vel']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = SolverConfig(\n",
    "        target_precision=0.0005, # Very strict\n",
    "        max_iter_per_stage=150,  # Give it time\n",
    "        min_grad_norm=1e-5,      # Much lower threshold (was 1e-3)\n",
    "        warmup_steps=20,         # Force 20 steps per stage minimum\n",
    "        epsilon_schedule=[2.0, 0.5, 0.0]\n",
    "    )\n",
    "    solve_with_controls(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bfcb6-5c1f-4810-9652-abda91493ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "import optax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "from typing import NamedTuple, List, Dict\n",
    "\n",
    "# ... [MatrixAlgebra, CartesianBox, Operators, etc. same as before] ...\n",
    "# (Copying minimal boilerplate for runnable context)\n",
    "\n",
    "class MatrixAlgebra:\n",
    "    def __init__(self, p, q, r=0):\n",
    "        self.p, self.q, self.r = p, q, r\n",
    "        self.alg = Algebra(p, q, r)\n",
    "        self.dim = len(self.alg)\n",
    "        self.basis_names = [f'e{i+1}' for i in range(p + q + r)]\n",
    "        matrices = []\n",
    "        for name in self.basis_names:\n",
    "            e_k = self.alg.blades[name]\n",
    "            cols = []\n",
    "            for i in range(self.dim):\n",
    "                b_i = self.alg.multivector({i: 1})\n",
    "                res = e_k * b_i\n",
    "                dense_col = jnp.zeros(self.dim)\n",
    "                for bin_key, val in res.items(): dense_col = dense_col.at[bin_key].set(val)\n",
    "                cols.append(dense_col)\n",
    "            matrices.append(jnp.stack(cols, axis=1))\n",
    "        self.basis_matrices = jnp.stack(matrices)\n",
    "    def __hash__(self): return hash((self.p, self.q, self.r))\n",
    "    def __eq__(self, o): return (self.p, self.q, self.r) == (o.p, o.q, o.r)\n",
    "\n",
    "class CartesianBox:\n",
    "    def __init__(self, size, dx):\n",
    "        self.size, self.dx = size, dx\n",
    "        xs = jnp.linspace(0, size*dx, size)\n",
    "        self.X, self.Y = jnp.meshgrid(xs, xs, indexing='xy')\n",
    "    def __hash__(self): return hash((self.size, self.dx))\n",
    "    def __eq__(self, o): return (self.size, self.dx) == (o.size, o.dx)\n",
    "    @property\n",
    "    def coordinates(self): return (self.X, self.Y)\n",
    "    def gradients(self, u):\n",
    "        u_pad = jnp.pad(u, ((1, 1), (1, 1), (0, 0)), mode='constant')\n",
    "        u_c = u_pad[1:-1, 1:-1]; dx = self.dx\n",
    "        dx_f = (u_pad[1:-1, 2:] - u_c)/dx; dy_f = (u_pad[2:, 1:-1] - u_c)/dx\n",
    "        dx_b = (u_c - u_pad[1:-1, 0:-2])/dx; dy_b = (u_c - u_pad[0:-2, 1:-1])/dx\n",
    "        lap = (u_pad[2:, 1:-1] + u_pad[0:-2, 1:-1] + u_pad[1:-1, 2:] + u_pad[1:-1, 0:-2] - 4*u_c)/(dx**2)\n",
    "        return ([dx_f, dy_f], [dx_b, dy_b], lap)\n",
    "    def enforce_boundaries(self, u):\n",
    "        u = u.at[0].set(0); u = u.at[-1].set(0); u = u.at[:, 0].set(0); u = u.at[:, -1].set(0)\n",
    "        return u\n",
    "\n",
    "GRID_SIZE, DX, DT, DURATION_STEPS, IDX_P = 100, 0.1, 0.0001, 1200, 0\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra'])\n",
    "def universal_pde_kernel(u, grads, lap, params_dict, algebra):\n",
    "    rate = jnp.zeros_like(u)\n",
    "    for i, grad in enumerate(grads):\n",
    "        if i >= len(algebra.basis_matrices): break\n",
    "        rate = rate - params_dict['c'] * jnp.einsum('kj,...j->...k', algebra.basis_matrices[i], grad)\n",
    "    rate = rate + params_dict['epsilon'] * lap - params_dict['V'] * u\n",
    "    return rate\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold'])\n",
    "def maccormack_step(u, dt, params, algebra, manifold):\n",
    "    g_f, g_b, lap = manifold.gradients(u)\n",
    "    k1 = universal_pde_kernel(u, g_f, lap, params, algebra)\n",
    "    u_p = u + k1 * dt\n",
    "    _, g_b_p, lap_p = manifold.gradients(u_p)\n",
    "    k2 = universal_pde_kernel(u_p, g_b_p, lap_p, params, algebra)\n",
    "    return manifold.enforce_boundaries(0.5 * (u + u_p + k2 * dt))\n",
    "\n",
    "@functools.partial(jit, static_argnames=['algebra', 'manifold'])\n",
    "def run_simulation(learn_params, hyper_params, algebra, manifold):\n",
    "    X, Y = manifold.coordinates\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    x0, y0 = learn_params['pos']\n",
    "    vx, vy = learn_params['vel']\n",
    "    pde_params = {'c': learn_params['c'], 'V': learn_params['V'], 'epsilon': hyper_params['epsilon']}\n",
    "    \n",
    "    def body_fn(carry, step_idx):\n",
    "        u_next = maccormack_step(carry, DT, pde_params, algebra, manifold)\n",
    "        t = step_idx * DT\n",
    "        # Source injection\n",
    "        src = jnp.exp(-((X-(x0+vx*t))**2 + (Y-(y0+vy*t))**2)/4.5) * jnp.exp(-(step_idx-50)**2/800.0) * 100.0 * DT\n",
    "        u_next = u_next.at[..., 0].add(src)\n",
    "        return u_next, u_next[..., 0]\n",
    "    return lax.scan(body_fn, u, jnp.arange(DURATION_STEPS))[1]\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PRECISION CONFIG & LOGIC\n",
    "# ==============================================================================\n",
    "\n",
    "class ConvergenceConfig(NamedTuple):\n",
    "    # Instead of one \"tolerance\", we have one for each physical type\n",
    "    tol_pos: float  # Stop if position changes < X meters\n",
    "    tol_vel: float  # Stop if velocity changes < X m/s\n",
    "    tol_c: float    # Stop if speed of sound changes < X m/s\n",
    "    tol_V: float    # Stop if damping changes < X\n",
    "    \n",
    "    max_iter: int\n",
    "    warmup: int\n",
    "    epsilon_schedule: List[float]\n",
    "\n",
    "def solve_precision(config: ConvergenceConfig):\n",
    "    algebra = MatrixAlgebra(2, 0)\n",
    "    manifold = CartesianBox(GRID_SIZE, DX)\n",
    "    \n",
    "    # Ground Truth\n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0]), 'c': 343.0, 'V': 0.5}\n",
    "    obs_data = run_simulation(TRUE_PARAMS, {'epsilon': 0.0}, algebra, manifold)[:, 90, 10] # Tiny hack for speed/syntax\n",
    "    # Re-run properly for full sensors if needed, but keeping it simple for logic demo\n",
    "    # Let's do it right:\n",
    "    SENSORS = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "    true_hist = run_simulation(TRUE_PARAMS, {'epsilon': 0.0}, algebra, manifold)\n",
    "    obs_data = true_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "\n",
    "    # Optimizer\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0]), 'c': 300.0, 'V': 0.0}\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.multi_transform(\n",
    "            {'pos': optax.adam(0.1), 'vel': optax.adam(5.0), 'c': optax.adam(1.0), 'V': optax.adam(0.5)},\n",
    "            {'pos':'pos', 'vel':'vel', 'c':'c', 'V':'V'}\n",
    "        )\n",
    "    )\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    def loss_fn(params, eps):\n",
    "        sim_hist = run_simulation(params, {'epsilon': eps}, algebra, manifold)\n",
    "        sim_data = sim_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "        safe_eps = 1e-6\n",
    "        sim_norm = (sim_data - jnp.mean(sim_data, 0)) / (jnp.std(sim_data, 0) + safe_eps)\n",
    "        obs_norm = (obs_data - jnp.mean(obs_data, 0)) / (jnp.std(obs_data, 0) + safe_eps)\n",
    "        \n",
    "        pos = params['pos']\n",
    "        bounds = jnp.sum(jnp.maximum(0, -pos)) + jnp.sum(jnp.maximum(0, pos - GRID_SIZE*DX))\n",
    "        return (1.0 - jnp.mean(sim_norm * obs_norm)) + bounds\n",
    "\n",
    "    print(f\"\\n--- Starting Precision Search ---\")\n",
    "    \n",
    "    for stage, eps in enumerate(config.epsilon_schedule):\n",
    "        print(f\"\\n>>> STAGE {stage} (Epsilon={eps}) <<<\")\n",
    "        \n",
    "        for i in range(config.max_iter):\n",
    "            loss, grads = value_and_grad(loss_fn)(guess, eps)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, guess)\n",
    "            \n",
    "            # --- THE MAGIC: Check Update Magnitudes ---\n",
    "            # We check how much the optimizer *actually moved* the parameters this step\n",
    "            # This handles learning rates automatically.\n",
    "            \n",
    "            # Apply updates to get new guess\n",
    "            new_guess = optax.apply_updates(guess, updates)\n",
    "            \n",
    "            # Calculate shift per parameter\n",
    "            diffs = {\n",
    "                'pos': jnp.linalg.norm(new_guess['pos'] - guess['pos']),\n",
    "                'vel': jnp.linalg.norm(new_guess['vel'] - guess['vel']),\n",
    "                'c':   jnp.abs(new_guess['c'] - guess['c']),\n",
    "                'V':   jnp.abs(new_guess['V'] - guess['V'])\n",
    "            }\n",
    "            \n",
    "            guess = new_guess\n",
    "            \n",
    "            # --- CONVERGENCE CHECK ---\n",
    "            is_stable = (\n",
    "                diffs['pos'] < config.tol_pos and\n",
    "                diffs['vel'] < config.tol_vel and\n",
    "                diffs['c']   < config.tol_c and\n",
    "                diffs['V']   < config.tol_V\n",
    "            )\n",
    "            \n",
    "            # Don't stop during warmup\n",
    "            if i >= config.warmup and is_stable:\n",
    "                print(f\"   [CONVERGED] All parameters stable at Iter {i}\")\n",
    "                print(f\"      Deltas: Pos={diffs['pos']:.5f} Vel={diffs['vel']:.5f} c={diffs['c']:.5f} V={diffs['V']:.5f}\")\n",
    "                break\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"   Iter {i}: L={loss:.5f}\")\n",
    "                print(f\"      Est: Vel={guess['vel']} (Delta: {diffs['vel']:.4f})\")\n",
    "                print(f\"      Est: V={guess['V']:.2f} (Delta: {diffs['V']:.4f})\")\n",
    "\n",
    "    print(\"\\n--- FINAL ---\")\n",
    "    print(f\"True: Vel={TRUE_PARAMS['vel']}, V={TRUE_PARAMS['V']}\")\n",
    "    print(f\"Est : Vel={guess['vel']}, V={guess['V']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define tolerances based on physics units\n",
    "    config = ConvergenceConfig(\n",
    "        tol_pos=0.001,  # 1 mm stability\n",
    "        tol_vel=0.01,   # 1 cm/s stability (Forces it to grind velocity!)\n",
    "        tol_c=0.01,     # 1 cm/s stability for sound speed\n",
    "        tol_V=0.0001,   # Very strict stability for damping\n",
    "        \n",
    "        max_iter=200,   # Allow long grind\n",
    "        warmup=30,      # Don't quit early\n",
    "        epsilon_schedule=[2.0, 0.5, 0.0]\n",
    "    )\n",
    "    solve_precision(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b5bbc-baa2-44c9-9928-7201563103f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0a266-ce40-4caa-a5c1-8505024dc635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
