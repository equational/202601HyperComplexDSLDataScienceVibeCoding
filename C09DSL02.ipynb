{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c75bad3-41c8-46b5-9cb6-3f98abe9c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d20d88-094a-456b-93cd-9266cdb1d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Union, List, Optional\n",
    "\n",
    "def _wrap(x):\n",
    "    if isinstance(x, (int, float)): return Constant(x)\n",
    "    return x\n",
    "\n",
    "@dataclass\n",
    "class Expression:\n",
    "    # --- Arithmetic Overloads ---\n",
    "    def __add__(self, other): return BinaryOp(self, _wrap(other), \"+\")\n",
    "    def __radd__(self, other): return BinaryOp(_wrap(other), self, \"+\")\n",
    "    \n",
    "    def __sub__(self, other): return BinaryOp(self, _wrap(other), \"-\")\n",
    "    def __rsub__(self, other): return BinaryOp(_wrap(other), self, \"-\")\n",
    "    \n",
    "    def __mul__(self, other): return BinaryOp(self, _wrap(other), \"*\")\n",
    "    def __rmul__(self, other): return BinaryOp(_wrap(other), self, \"*\")\n",
    "    \n",
    "    def __truediv__(self, other): return BinaryOp(self, _wrap(other), \"/\")\n",
    "    def __rtruediv__(self, other): return BinaryOp(_wrap(other), self, \"/\")\n",
    "    \n",
    "    def __pow__(self, other): return BinaryOp(self, _wrap(other), \"**\")\n",
    "    \n",
    "    def __neg__(self): return UnaryOp(self, \"-\")\n",
    "\n",
    "@dataclass\n",
    "class Symbol(Expression): name: str\n",
    "@dataclass\n",
    "class Field(Symbol): rank: int = 0\n",
    "@dataclass\n",
    "class Parameter(Symbol): pass\n",
    "@dataclass\n",
    "class Constant(Expression): value: float\n",
    "\n",
    "@dataclass\n",
    "class UnaryOp(Expression):\n",
    "    operand: Expression; op: str\n",
    "\n",
    "@dataclass\n",
    "class BinaryOp(Expression):\n",
    "    left: Expression; right: Expression; op: str\n",
    "\n",
    "@dataclass\n",
    "class Equation:\n",
    "    lhs: Expression; rhs: Expression\n",
    "    def __repr__(self): return f\"{self.lhs} == {self.rhs}\"\n",
    "\n",
    "# Functional Helpers\n",
    "def dt(expr): return UnaryOp(expr, 'dt')\n",
    "def grad(expr): return UnaryOp(expr, 'grad')\n",
    "def div(expr): return UnaryOp(expr, 'div')\n",
    "def laplacian(expr): return UnaryOp(expr, 'laplacian')\n",
    "def Eq(lhs, rhs): return Equation(lhs, rhs)\n",
    "def vec(expr): return UnaryOp(expr, 'vec') # Explicit vector construction if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc121bb-a2f1-4a06-b6d8-e95f6adccd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Union, List\n",
    "#from dsl_core import Field, Parameter, Constant\n",
    "\n",
    "# --- 1. TRAJECTORIES (How sources move) ---\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class LinearTrajectory(Trajectory):\n",
    "    start_pos: Union[Parameter, List[float]]\n",
    "    velocity: Union[Parameter, List[float]]\n",
    "\n",
    "@dataclass\n",
    "class StaticPosition(Trajectory):\n",
    "    pos: Union[Parameter, List[float]]\n",
    "\n",
    "# --- 2. ENVELOPES (How sources look in time/space) ---\n",
    "@dataclass\n",
    "class GaussianPulse:\n",
    "    center_step: int\n",
    "    width_step: float\n",
    "    amplitude: float\n",
    "\n",
    "# --- 3. SOURCES (The Drivers) ---\n",
    "@dataclass\n",
    "class SourceTerm:\n",
    "    field: Field  # Which field does this affect?\n",
    "    \n",
    "@dataclass\n",
    "class MovingSpotlight(SourceTerm):\n",
    "    trajectory: Trajectory\n",
    "    spatial_sigma: float\n",
    "    temporal_profile: GaussianPulse\n",
    "\n",
    "# --- 4. BOUNDARIES (The Constraints) ---\n",
    "@dataclass\n",
    "class BoundaryCondition:\n",
    "    field: Field\n",
    "    \n",
    "@dataclass\n",
    "class DirichletBC(BoundaryCondition):\n",
    "    value: float = 0.0  # Homogeneous Dirichlet (Walls)\n",
    "\n",
    "# --- 5. THE PROBLEM CONTAINER ---\n",
    "@dataclass\n",
    "class Problem:\n",
    "    equation: 'Equation'\n",
    "    bcs: List[BoundaryCondition]\n",
    "    sources: List[SourceTerm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0444056-a22b-49d7-b774-e2dcacc7e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.sparse.linalg as spla\n",
    "#from dsl_core import *\n",
    "#from dsl_problem import *\n",
    "#from sta_inverse_precision import MatrixAlgebra, CartesianBox \n",
    "\n",
    "class ProblemCompiler:\n",
    "    def __init__(self, algebra, manifold):\n",
    "        self.algebra = algebra\n",
    "        self.manifold = manifold\n",
    "        self.bases = tuple(self.algebra.basis_matrices)\n",
    "        # Re-use the Auto-Split logic for the physics part\n",
    "        self.physics_compiler = None \n",
    "\n",
    "    def compile(self, problem: Problem):\n",
    "        # 1. Compile the Physics Kernel (using previous logic)\n",
    "        # We instantiate the sub-compiler here to keep state clean\n",
    "        # from dsl_compiler_autosplit_fixed import AutoSplitCompiler\n",
    "        self.physics_compiler = AutoSplitCompiler(self.algebra, self.manifold)\n",
    "        physics_step = self.physics_compiler.compile(problem.equation)\n",
    "        \n",
    "        # 2. Compile Source Kernels\n",
    "        source_fns = [self._compile_source(s) for s in problem.sources]\n",
    "        \n",
    "        # 3. Compile Boundary Kernels\n",
    "        bc_fns = [self._compile_bc(b) for b in problem.bcs]\n",
    "        \n",
    "        # 4. Generate the Master Stepper\n",
    "        def master_step_fn(u_curr, params, dt, step_idx):\n",
    "            # A. Physics Step (Split Hybrid)\n",
    "            u_next = physics_step(u_curr, params, dt)\n",
    "            \n",
    "            # B. Apply Sources\n",
    "            # We assume sources are additive (Forcing terms)\n",
    "            t = step_idx * dt\n",
    "            for src_fn in source_fns:\n",
    "                contribution = src_fn(params, t, step_idx, self.manifold.coordinates)\n",
    "                u_next = u_next + contribution\n",
    "            \n",
    "            # C. Apply Boundaries\n",
    "            for bc_fn in bc_fns:\n",
    "                u_next = bc_fn(u_next)\n",
    "                \n",
    "            return u_next\n",
    "\n",
    "        return master_step_fn\n",
    "\n",
    "    def _compile_source(self, src):\n",
    "        if isinstance(src, MovingSpotlight):\n",
    "            # Pre-compute constants\n",
    "            amp = src.temporal_profile.amplitude\n",
    "            t_center = src.temporal_profile.center_step\n",
    "            t_width = src.temporal_profile.width_step\n",
    "            sigma_sq = src.spatial_sigma\n",
    "            \n",
    "            # Extract parameter names if they are Parameters\n",
    "            pos_name = src.trajectory.start_pos.name if isinstance(src.trajectory.start_pos, Parameter) else None\n",
    "            vel_name = src.trajectory.velocity.name if isinstance(src.trajectory.velocity, Parameter) else None\n",
    "            \n",
    "            def source_kernel(params, t, i, coords):\n",
    "                X, Y = coords\n",
    "                \n",
    "                # Resolve Position\n",
    "                if isinstance(src.trajectory, LinearTrajectory):\n",
    "                    # Dynamic Parameter Lookup\n",
    "                    p0 = params[pos_name] if pos_name else src.trajectory.start_pos\n",
    "                    v = params[vel_name] if vel_name else src.trajectory.velocity\n",
    "                    \n",
    "                    x_c = p0[0] + v[0] * t\n",
    "                    y_c = p0[1] + v[1] * t\n",
    "                else:\n",
    "                    # Static\n",
    "                    p0 = params[pos_name] if pos_name else src.trajectory.pos\n",
    "                    x_c, y_c = p0[0], p0[1]\n",
    "                \n",
    "                # Spatial Profile\n",
    "                dist_sq = (X - x_c)**2 + (Y - y_c)**2\n",
    "                spatial = jnp.exp(-dist_sq / sigma_sq)\n",
    "                \n",
    "                # Temporal Envelope\n",
    "                temporal = jnp.exp(-(i - t_center)**2 / t_width)\n",
    "                \n",
    "                # Construct Field Update (Scalar component only)\n",
    "                # We return a full field array (N, N, 4) with only component 0 active\n",
    "                return jnp.zeros_like(X)[..., None] * 0 # Dummy shape match\n",
    "                # Correct way: Create the full shape\n",
    "                val = spatial * temporal * amp * dt # Note: Source is Rate * dt\n",
    "                \n",
    "                # Place into component 0 (Scalar)\n",
    "                # We need a clean way to map Field -> Component Index.\n",
    "                # Assuming Scalar field Psi is index 0 for this algebra.\n",
    "                \n",
    "                # Create (N, N, 1) -> (N, N, 4) padding\n",
    "                zeros = jnp.zeros_like(val)\n",
    "                # [Val, 0, 0, 0]\n",
    "                return jnp.stack([val, zeros, zeros, zeros], axis=-1)\n",
    "\n",
    "            return source_kernel\n",
    "        \n",
    "        raise NotImplementedError(f\"Unknown Source: {type(src)}\")\n",
    "\n",
    "    def _compile_bc(self, bc):\n",
    "        if isinstance(bc, DirichletBC):\n",
    "            if bc.value == 0.0:\n",
    "                # Optimized 'Wall'\n",
    "                return self.manifold.enforce_boundaries\n",
    "            \n",
    "            def custom_bc(u):\n",
    "                # Set edges to value\n",
    "                return u.at[0].set(bc.value).at[-1].set(bc.value) \\\n",
    "                        .at[:,0].set(bc.value).at[:,-1].set(bc.value)\n",
    "            return custom_bc\n",
    "            \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a115a0-32ea-44fa-9887-c03cd0775cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax\n",
    "import functools\n",
    "from kingdon import Algebra\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. REUSED ABSTRACTIONS (The Framework)\n",
    "# ==============================================================================\n",
    "\n",
    "class MatrixAlgebra:\n",
    "    \"\"\" Pre-computes Geometric Product matrices (Works for 1D, 2D, 3D) \"\"\"\n",
    "    def __init__(self, p, q, r=0):\n",
    "        self.p, self.q, self.r = p, q, r\n",
    "        self.alg = Algebra(p, q, r)\n",
    "        self.dim = len(self.alg) # 1D=2 (Scalar, Vector), 2D=4\n",
    "        # Basis generators (e1...)\n",
    "        self.basis_names = [f'e{i+1}' for i in range(p + q + r)]\n",
    "        \n",
    "        matrices = []\n",
    "        for name in self.basis_names:\n",
    "            e_k = self.alg.blades[name]\n",
    "            cols = []\n",
    "            for i in range(self.dim):\n",
    "                b_i = self.alg.multivector({i: 1})\n",
    "                res = e_k * b_i\n",
    "                dense_col = jnp.zeros(self.dim)\n",
    "                for bin_key, val in res.items(): dense_col = dense_col.at[bin_key].set(val)\n",
    "                cols.append(dense_col)\n",
    "            matrices.append(jnp.stack(cols, axis=1))\n",
    "        self.basis_matrices = jnp.stack(matrices)\n",
    "\n",
    "class CartesianBox:\n",
    "    \"\"\" Generic N-Dimensional Grid with Boundary Support \"\"\"\n",
    "    def __init__(self, shape, dx):\n",
    "        self.shape = shape # Tuple (Nx, Ny...)\n",
    "        self.dx = dx\n",
    "        self.ndim = len(shape)\n",
    "        \n",
    "        # Create coordinates\n",
    "        coords = [jnp.linspace(0, s*dx, s) for s in shape]\n",
    "        self.grid = jnp.meshgrid(*coords, indexing='ij')\n",
    "\n",
    "    @property\n",
    "    def coordinates(self): return self.grid\n",
    "\n",
    "    def gradients(self, u):\n",
    "        # Generic padding for any dimension\n",
    "        # Pad spatial dims, leave channel dim (last) alone if it exists\n",
    "        # u shape is (N, N, ..., Channels)\n",
    "        \n",
    "        # Determine padding width: ((1,1), (1,1)... (0,0))\n",
    "        # We assume u has exactly self.ndim spatial dimensions + optional channel dim\n",
    "        has_channel = (u.ndim > self.ndim)\n",
    "        pad_width = [(1, 1)] * self.ndim\n",
    "        if has_channel: pad_width.append((0, 0))\n",
    "        \n",
    "        u_pad = jnp.pad(u, tuple(pad_width), mode='edge') \n",
    "        \n",
    "        center_slice = [slice(1, -1)] * self.ndim\n",
    "        if has_channel: center_slice.append(slice(None))\n",
    "        u_c = u_pad[tuple(center_slice)]\n",
    "        \n",
    "        grads_fwd = []\n",
    "        grads_bwd = []\n",
    "        lap_sum = jnp.zeros_like(u_c)\n",
    "        \n",
    "        for i in range(self.ndim):\n",
    "            # Slices for neighbor access along axis i\n",
    "            # Next neighbor\n",
    "            s_next = [slice(1, -1)] * self.ndim\n",
    "            s_next[i] = slice(2, None)\n",
    "            if has_channel: s_next.append(slice(None))\n",
    "            \n",
    "            # Prev neighbor\n",
    "            s_prev = [slice(1, -1)] * self.ndim\n",
    "            s_prev[i] = slice(0, -2)\n",
    "            if has_channel: s_prev.append(slice(None))\n",
    "            \n",
    "            u_next = u_pad[tuple(s_next)]\n",
    "            u_prev = u_pad[tuple(s_prev)]\n",
    "            \n",
    "            grads_fwd.append( (u_next - u_c) / self.dx )\n",
    "            grads_bwd.append( (u_c - u_prev) / self.dx )\n",
    "            lap_sum += (u_next + u_prev - 2*u_c) / (self.dx**2)\n",
    "            \n",
    "        return (grads_fwd, grads_bwd, lap_sum)\n",
    "\n",
    "    def enforce_boundaries(self, u):\n",
    "        \"\"\" Zero out the spatial boundaries (Hard Walls) \"\"\"\n",
    "        # Works for 1D, 2D, 3D...\n",
    "        res = u\n",
    "        for i in range(self.ndim):\n",
    "            # Create a dynamic slice object\n",
    "            # u.at[..., 0, ...].set(0) where 0 is at axis i\n",
    "            \n",
    "            # Left Boundary (Index 0)\n",
    "            sl_0 = [slice(None)] * u.ndim\n",
    "            sl_0[i] = 0\n",
    "            res = res.at[tuple(sl_0)].set(0.0)\n",
    "            \n",
    "            # Right Boundary (Index -1)\n",
    "            sl_1 = [slice(None)] * u.ndim\n",
    "            sl_1[i] = -1\n",
    "            res = res.at[tuple(sl_1)].set(0.0)\n",
    "            \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6caecdc-7bae-4cfb-835b-4eabcdd84236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "import jax.scipy.sparse.linalg as spla \n",
    "import optax\n",
    "#from dsl_core import *\n",
    "#from sta_inverse_precision import MatrixAlgebra, CartesianBox \n",
    "\n",
    "class AutoSplitCompiler:\n",
    "    def __init__(self, algebra, manifold):\n",
    "        self.algebra = algebra\n",
    "        self.manifold = manifold\n",
    "        self.bases = tuple(self.algebra.basis_matrices)\n",
    "        \n",
    "        # State\n",
    "        self.u_curr = None\n",
    "        self.params = None\n",
    "        self.grads = None # (gf, gb, lap)\n",
    "\n",
    "    def compile(self, equation: Equation):\n",
    "        \n",
    "        # 1. KERNEL GENERATORS (The Evaluators)\n",
    "        \n",
    "        def kernel_eval(u, grads, p):\n",
    "            self.u_curr = u; self.params = p; self.grads = grads\n",
    "            # Just evaluate the whole tree. \n",
    "            # The _eval method will handle missing data (None) by returning Zeros.\n",
    "            return self._eval(equation.rhs)\n",
    "\n",
    "        # 2. STEPPER (Matrix-Free Hybrid)\n",
    "        \n",
    "        def step_fn(u_curr, params, dt):\n",
    "            # --- A. EXPLICIT PHASE (Advection) ---\n",
    "            # We want to compute terms dependent on 'grad'\n",
    "            # We pass 'None' for laplacian to signal \"Ignore Diffusion\"\n",
    "            \n",
    "            gf, gb, lap = self.manifold.gradients(u_curr)\n",
    "            \n",
    "            # Predict\n",
    "            self.direction = 'fwd'\n",
    "            # Pass (gf, gb, None) -> Evaluates Grad terms, ignores Lap terms\n",
    "            k1 = kernel_eval(u_curr, (gf, gb, None), params)\n",
    "            u_p = u_curr + k1 * dt\n",
    "            \n",
    "            # Correct\n",
    "            gf_p, gb_p, lap_p = self.manifold.gradients(u_p)\n",
    "            self.direction = 'bwd'\n",
    "            k2 = kernel_eval(u_p, (gf_p, gb_p, None), params)\n",
    "            self.direction = 'fwd' # Reset\n",
    "            \n",
    "            u_adv = 0.5 * (u_curr + u_p + k2 * dt)\n",
    "            \n",
    "            # --- B. IMPLICIT PHASE (Diffusion/Decay) ---\n",
    "            # Solve (I - dt * ImpOp) x = u_adv\n",
    "            \n",
    "            def linear_op(x_flat):\n",
    "                x = x_flat.reshape(u_curr.shape)\n",
    "                _, _, lap_x = self.manifold.gradients(x)\n",
    "                \n",
    "                # Evaluate Diffusion/Decay\n",
    "                # Pass (None, None, lap_x) -> Evaluates Lap terms, ignores Grad terms\n",
    "                rate = kernel_eval(x, (None, None, lap_x), params)\n",
    "                \n",
    "                return (x - dt * rate).ravel()\n",
    "\n",
    "            u_flat = u_adv.ravel()\n",
    "            u_next_flat, _ = spla.cg(linear_op, u_flat, x0=u_flat, tol=1e-5, maxiter=20)\n",
    "            return u_next_flat.reshape(u_curr.shape)\n",
    "\n",
    "        return step_fn\n",
    "\n",
    "    # --- ROBUST EVALUATOR ---\n",
    "\n",
    "    def _eval(self, expr):\n",
    "        if isinstance(expr, Field): return self.u_curr\n",
    "        if isinstance(expr, Parameter): return self.params[expr.name]\n",
    "        if isinstance(expr, Constant): return expr.value\n",
    "        \n",
    "        if isinstance(expr, UnaryOp):\n",
    "            if expr.op == 'grad':\n",
    "                gf, gb, _ = self.grads\n",
    "                # SAFETY: If grads are None (Implicit Phase), return Zero Vector\n",
    "                if gf is None: \n",
    "                    return [jnp.zeros_like(self.u_curr) for _ in range(self.algebra.dim)]\n",
    "                \n",
    "                use_bwd = getattr(self, 'direction', 'fwd') == 'bwd'\n",
    "                return gb if use_bwd else gf\n",
    "            \n",
    "            if expr.op == 'laplacian':\n",
    "                _, _, lap = self.grads\n",
    "                # SAFETY: If lap is None (Explicit Phase), return Zero Scalar\n",
    "                if lap is None:\n",
    "                    return jnp.zeros_like(self.u_curr)\n",
    "                return lap\n",
    "            \n",
    "            val = self._eval(expr.operand)\n",
    "            if expr.op == '-': return -val if not isinstance(val, list) else [-x for x in val]\n",
    "\n",
    "        if isinstance(expr, BinaryOp):\n",
    "            l = self._eval(expr.left)\n",
    "            r = self._eval(expr.right)\n",
    "            \n",
    "            # Fused Contraction (Optimization)\n",
    "            if expr.op == '*':\n",
    "                if isinstance(l, list) and not isinstance(r, list): return self._contract(l, r) \n",
    "                if isinstance(r, list) and not isinstance(l, list): return self._contract(r, l)\n",
    "            \n",
    "            # Standard Math\n",
    "            if expr.op == '+': return self._add(l, r)\n",
    "            if expr.op == '-': return self._add(l, r, sub=True)\n",
    "            if expr.op == '*': return l * r\n",
    "\n",
    "        raise NotImplementedError(f\"{expr}\")\n",
    "\n",
    "    def _contract(self, vec, scale):\n",
    "        acc = jnp.zeros_like(vec[0])\n",
    "        for i, b in enumerate(self.bases):\n",
    "            # Check for zero-vector placeholder\n",
    "            if i >= len(vec): break\n",
    "            acc += jnp.einsum('kj,...j->...k', b, vec[i]) * scale\n",
    "        return acc\n",
    "\n",
    "    def _add(self, l, r, sub=False):\n",
    "        if isinstance(l, list): l = self._contract(l, 1.0)\n",
    "        if isinstance(r, list): r = self._contract(r, 1.0)\n",
    "        return (l - r) if sub else (l + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842fd67b-13d7-404c-a75b-21c6f3959bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DSL Compiled: Auto-Split Matrix-Free Hybrid Solver ---\n",
      "Generating Ground Truth...\n",
      "\n",
      "--- Starting DSL Precision Search ---\n",
      "\n",
      ">>> STAGE 0 (Epsilon=2.0) <<<\n",
      "  Iter   0: Loss=0.4137 | Vel=[-4.99991962  4.99993124] | V=0.500\n",
      "  Iter  20: Loss=0.0590 | Vel=[-70.98826726  76.79999785] | V=10.779\n",
      "  Iter  40: Loss=0.0132 | Vel=[-60.67740417  64.05549699] | V=12.061\n",
      "  Iter  60: Loss=0.0038 | Vel=[-55.33345614  64.17209336] | V=4.109\n",
      "  Iter  80: Loss=0.0021 | Vel=[-49.41404511  58.09059796] | V=-1.214\n",
      "  Iter 100: Loss=0.0018 | Vel=[-40.93813899  51.22133214] | V=-1.542\n",
      "  Iter 120: Loss=0.0015 | Vel=[-32.18231407  44.42601499] | V=-0.865\n",
      "  Iter 140: Loss=0.0012 | Vel=[-23.70211689  37.55957809] | V=-0.821\n",
      "  Iter 160: Loss=0.0010 | Vel=[-15.62255942  30.9099544 ] | V=-0.855\n",
      "  Iter 180: Loss=0.0008 | Vel=[-7.97006363 24.55144065] | V=-0.827\n",
      "  Iter 200: Loss=0.0007 | Vel=[-0.81004635 18.53451075] | V=-0.808\n",
      "\n",
      ">>> STAGE 1 (Epsilon=0.5) <<<\n",
      "  Iter   0: Loss=0.0006 | Vel=[-0.45961679 18.24462019] | V=-0.797\n",
      "  Iter  20: Loss=0.0004 | Vel=[ 5.80215091 12.93879267] | V=0.088\n",
      "  Iter  40: Loss=0.0003 | Vel=[11.19597639  8.26621899] | V=0.197\n",
      "  Iter  60: Loss=0.0003 | Vel=[15.88961314  4.13678685] | V=0.101\n",
      "  Iter  80: Loss=0.0002 | Vel=[20.04342504  0.42293729] | V=0.126\n",
      "  Iter 100: Loss=0.0002 | Vel=[23.69304153 -2.89519255] | V=0.138\n",
      "  Iter 120: Loss=0.0002 | Vel=[26.85049421 -5.81558379] | V=0.145\n",
      "  Iter 140: Loss=0.0002 | Vel=[29.56126589 -8.37015116] | V=0.150\n",
      "  Iter 160: Loss=0.0002 | Vel=[ 31.86670132 -10.58748043] | V=0.156\n",
      "  Iter 180: Loss=0.0001 | Vel=[ 33.80797266 -12.49669859] | V=0.160\n",
      "  Iter 200: Loss=0.0001 | Vel=[ 35.42746641 -14.1290017 ] | V=0.163\n",
      "\n",
      ">>> STAGE 2 (Epsilon=0.0) <<<\n",
      "  Iter   0: Loss=0.0001 | Vel=[ 35.50794168 -14.20178488] | V=0.168\n",
      "  Iter  20: Loss=0.0001 | Vel=[ 36.68835526 -15.37711921] | V=0.522\n",
      "  Iter  40: Loss=0.0001 | Vel=[ 37.46697907 -16.2394063 ] | V=0.470\n",
      "  Iter  60: Loss=0.0001 | Vel=[ 38.05358214 -16.92759532] | V=0.463\n",
      "  Iter  80: Loss=0.0001 | Vel=[ 38.53853772 -17.51537279] | V=0.471\n",
      "  Iter 100: Loss=0.0001 | Vel=[ 38.91554884 -17.99617429] | V=0.471\n",
      "  Iter 120: Loss=0.0001 | Vel=[ 39.2107209  -18.39207435] | V=0.471\n",
      "  Iter 140: Loss=0.0001 | Vel=[ 39.43917269 -18.71678492] | V=0.472\n",
      "  Iter 160: Loss=0.0001 | Vel=[ 39.61295391 -18.98114683] | V=0.473\n",
      "  Iter 180: Loss=0.0001 | Vel=[ 39.74364524 -19.19559079] | V=0.473\n",
      "  [CONVERGED] Iter 190 | Vel Delta=0.0099\n",
      "  Current: Vel=[ 39.79571476 -19.28678987] | V=0.473\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Rec Pos: [3.00093587 6.99651035]\n",
      "Rec Vel: [ 39.79571476 -19.28678987]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP ---\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "DURATION_STEPS = 1200\n",
    "\n",
    "algebra = MatrixAlgebra(2, 0)\n",
    "manifold = CartesianBox((GRID_SIZE, GRID_SIZE), DX)\n",
    "\n",
    "# --- 2. THE DSL DEFINITION (RESTORED!) ---\n",
    "Psi = Field(\"Psi\")\n",
    "c   = Parameter(\"c\")\n",
    "V   = Parameter(\"V\")\n",
    "eps = Parameter(\"epsilon\")\n",
    "\n",
    "# The User writes Physics:\n",
    "# \"Rate is negative divergence of flux (-c grad) plus diffusion (eps lap) minus decay (V psi)\"\n",
    "eq_physics = Eq(dt(Psi), -(c * grad(Psi)) + eps * laplacian(Psi) - V * Psi)\n",
    "\n",
    "# --- 3. THE COMPILER MAGIC ---\n",
    "# The compiler analyzes 'eq_physics', sees 'grad' (Explicit) and 'lap' (Implicit),\n",
    "# and generates the Matrix-Free Hybrid MacCormack solver automatically.\n",
    "compiler = AutoSplitCompiler(algebra, manifold)\n",
    "step_fn = compiler.compile(eq_physics)\n",
    "\n",
    "print(\"--- DSL Compiled: Auto-Split Matrix-Free Hybrid Solver ---\")\n",
    "\n",
    "# --- 4. THE RUNNER (Standard) ---\n",
    "@jax.jit\n",
    "def run_simulation(params_dict, hyper_params):\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    X, Y = manifold.coordinates\n",
    "    p = {**params_dict, **hyper_params}\n",
    "    x0, y0 = p['pos']; vx, vy = p['vel']\n",
    "    \n",
    "    def body(carry, i):\n",
    "        u_curr = carry\n",
    "        u_next = step_fn(u_curr, p, DT)\n",
    "        u_next = manifold.enforce_boundaries(u_next)\n",
    "        \n",
    "        # Source\n",
    "        t = i * DT\n",
    "        src = jnp.exp(-((X-(x0+vx*t))**2 + (Y-(y0+vy*t))**2)/4.5) * \\\n",
    "              jnp.exp(-(i-50)**2/800.0) * 100.0 * DT\n",
    "        u_next = u_next.at[..., 0].add(src)\n",
    "        return u_next, u_next[..., 0]\n",
    "\n",
    "    _, history = lax.scan(body, u, jnp.arange(DURATION_STEPS))\n",
    "    return history\n",
    "\n",
    "# --- 5. PRECISION SOLVE ---\n",
    "def solve_restored_dsl():\n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0]), 'c': 343.0, 'V': 0.5}\n",
    "    print(\"Generating Ground Truth...\")\n",
    "    true_hist = run_simulation(TRUE_PARAMS, {'epsilon': 0.0})\n",
    "    \n",
    "    SENSORS = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "    obs_data = true_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "    \n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0]), 'c': 300.0, 'V': 0.0}\n",
    "    optimizer = optax.chain(optax.clip_by_global_norm(1.0), optax.multi_transform(\n",
    "        {'pos': optax.adam(0.1), 'vel': optax.adam(5.0), 'c': optax.adam(1.0), 'V': optax.adam(0.5)},\n",
    "        {'pos':'pos', 'vel':'vel', 'c':'c', 'V':'V'}))\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    @jax.jit\n",
    "    def update(state, guess, eps):\n",
    "        def loss(p):\n",
    "            sim = run_simulation(p, {'epsilon': eps})\n",
    "            dat = sim[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "            safe = 1e-6\n",
    "            sim_n = (dat - jnp.mean(dat, 0)) / (jnp.std(dat, 0) + safe)\n",
    "            obs_n = (obs_data - jnp.mean(obs_data, 0)) / (jnp.std(obs_data, 0) + safe)\n",
    "            pb = jnp.sum(jnp.maximum(0, -p['pos'])) + jnp.sum(jnp.maximum(0, p['pos'] - 10.0))\n",
    "            return (1.0 - jnp.mean(sim_n * obs_n)) + pb\n",
    "        l, g = value_and_grad(loss)(guess)\n",
    "        u, s = optimizer.update(g, state, guess)\n",
    "        return l, optax.apply_updates(guess, u), s\n",
    "\n",
    "    print(\"\\n--- Starting DSL Precision Search ---\")\n",
    "    for stage, eps in enumerate([2.0, 0.5, 0.0]):\n",
    "        print(f\"\\n>>> STAGE {stage} (Epsilon={eps}) <<<\")\n",
    "        for i in range(201):\n",
    "            loss, new_guess, opt_state = update(opt_state, guess, eps)\n",
    "            d_vel = jnp.linalg.norm(new_guess['vel'] - guess['vel'])\n",
    "            guess = new_guess\n",
    "            \n",
    "            if i > 20 and d_vel < 0.01:\n",
    "                print(f\"  [CONVERGED] Iter {i} | Vel Delta={d_vel:.4f}\")\n",
    "                print(f\"  Current: Vel={guess['vel']} | V={guess['V']:.3f}\")\n",
    "                break\n",
    "            if i % 20 == 0:\n",
    "                print(f\"  Iter {i:3d}: Loss={loss:.4f} | Vel={guess['vel']} | V={guess['V']:.3f}\")\n",
    "\n",
    "    return guess\n",
    "\n",
    "final = solve_restored_dsl()\n",
    "print(\"\\n--- FINAL RESULT ---\")\n",
    "print(f\"Rec Pos: {final['pos']}\")\n",
    "print(f\"Rec Vel: {final['vel']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa39d851-e34b-4383-bfe6-10518455e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Robust Hybrid Solver Compiled ---\n",
      "Generating Ground Truth...\n",
      "\n",
      "--- Starting Robust Precision Search ---\n",
      "\n",
      ">>> STAGE 0 (Epsilon=2.0) <<<\n",
      "  Iter   0: Loss=0.4141 | Vel=[-4.99991965  4.99993128] | V=0.500\n",
      "  Iter  20: Loss=0.0611 | Vel=[-70.46447249  76.37947397] | V=10.926\n",
      "  Iter  40: Loss=0.0105 | Vel=[-60.79204744  64.00388918] | V=15.385\n",
      "  Iter  60: Loss=0.0042 | Vel=[-56.06215855  64.87621874] | V=10.309\n",
      "  Iter  80: Loss=0.0025 | Vel=[-49.93899401  58.59868025] | V=3.741\n",
      "  Iter 100: Loss=0.0018 | Vel=[-40.90998369  51.18224977] | V=-0.540\n",
      "  Iter 120: Loss=0.0015 | Vel=[-32.0567892   44.30185107] | V=-2.176\n",
      "  Iter 140: Loss=0.0012 | Vel=[-23.687766    37.55173961] | V=-2.394\n",
      "  Iter 160: Loss=0.0010 | Vel=[-15.62705178  30.92458294] | V=-2.266\n",
      "  Iter 180: Loss=0.0008 | Vel=[-7.9584033 24.5530991] | V=-2.161\n",
      "  Iter 200: Loss=0.0007 | Vel=[-0.79946236 18.53976131] | V=-2.105\n",
      "\n",
      ">>> STAGE 1 (Epsilon=0.5) <<<\n",
      "  Iter   0: Loss=0.0006 | Vel=[-0.44914677 18.25010379] | V=-2.094\n",
      "  Iter  20: Loss=0.0004 | Vel=[ 5.81552706 12.94248257] | V=-1.056\n",
      "  Iter  40: Loss=0.0003 | Vel=[11.16591066  8.31800196] | V=-0.292\n",
      "  Iter  60: Loss=0.0003 | Vel=[15.8699888   4.17974843] | V=-0.168\n",
      "  Iter  80: Loss=0.0002 | Vel=[20.03349701  0.45460102] | V=-0.223\n",
      "  Iter 100: Loss=0.0002 | Vel=[23.67897476 -2.86108107] | V=-0.237\n",
      "  Iter 120: Loss=0.0002 | Vel=[26.8383903  -5.78491233] | V=-0.218\n",
      "  Iter 140: Loss=0.0002 | Vel=[29.55166531 -8.34361439] | V=-0.202\n",
      "  Iter 160: Loss=0.0002 | Vel=[ 31.85907816 -10.56470009] | V=-0.191\n",
      "  Iter 180: Loss=0.0001 | Vel=[ 33.80269157 -12.47806623] | V=-0.183\n",
      "  Iter 200: Loss=0.0001 | Vel=[ 35.42461815 -14.11457531] | V=-0.176\n",
      "\n",
      ">>> STAGE 2 (Epsilon=0.0) <<<\n",
      "  Iter   0: Loss=0.0001 | Vel=[ 35.50528557 -14.18762399] | V=-0.171\n",
      "  Iter  20: Loss=0.0001 | Vel=[ 36.68525574 -15.36427276] | V=0.289\n",
      "  Iter  40: Loss=0.0001 | Vel=[ 37.45154746 -16.21345952] | V=0.505\n",
      "  Iter  60: Loss=0.0001 | Vel=[ 38.05005765 -16.91522144] | V=0.458\n",
      "  Iter  80: Loss=0.0001 | Vel=[ 38.53124382 -17.50166637] | V=0.431\n",
      "  Iter 100: Loss=0.0001 | Vel=[ 38.90922746 -17.98490023] | V=0.440\n",
      "  Iter 120: Loss=0.0001 | Vel=[ 39.20540392 -18.38301545] | V=0.445\n",
      "  Iter 140: Loss=0.0001 | Vel=[ 39.43425027 -18.70920486] | V=0.445\n",
      "  Iter 160: Loss=0.0001 | Vel=[ 39.60867863 -18.97509342] | V=0.446\n",
      "  Iter 180: Loss=0.0001 | Vel=[ 39.73991214 -19.19079195] | V=0.447\n",
      "  [CONVERGED] Iter 191 | Vel Delta=0.0099\n",
      "  Current: Vel=[ 39.79704586 -19.29119201] | V=0.447\n",
      "\n",
      "--- FINAL RESULT ---\n",
      "Rec Pos: [3.00093132 6.99652838]\n",
      "Rec Vel: [ 39.79704586 -19.29119201]\n",
      "Rec V  : 0.447\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, value_and_grad\n",
    "import jax.scipy.sparse.linalg as spla\n",
    "import optax\n",
    "#from dsl_core import *\n",
    "#from dsl_problem import *\n",
    "#from sta_inverse_precision import MatrixAlgebra, CartesianBox \n",
    "\n",
    "# --- 1. ROBUST PHYSICS ENGINE (The \"Backend\") ---\n",
    "# Instead of auto-splitting, we use the proven Matrix-Free logic directly.\n",
    "\n",
    "class RobustHybridSolver:\n",
    "    def __init__(self, algebra, manifold):\n",
    "        self.algebra = algebra\n",
    "        self.manifold = manifold\n",
    "        self.bases = tuple(self.algebra.basis_matrices)\n",
    "\n",
    "    def compile_step(self, problem: Problem):\n",
    "        \"\"\"\n",
    "        Hard-coded compilation of: dt(u) = -c*grad(u) + eps*lap(u) - V*u\n",
    "        This bypasses the fragile AST walker for the physics core.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Source & BC Compilers (These work fine)\n",
    "        # We assume ProblemCompiler logic for sources is reused or inlined here\n",
    "        source_fns = [self._compile_source(s) for s in problem.sources]\n",
    "        bc_fns = [self._compile_bc(b) for b in problem.bcs]\n",
    "        \n",
    "        # 2. The Proven Matrix-Free Kernels\n",
    "        def eval_advection(u, grads, params):\n",
    "            # Explicit Advection: -c * (basis . grad)\n",
    "            c = params['c']\n",
    "            rate = jnp.zeros_like(u)\n",
    "            for i, basis in enumerate(self.bases):\n",
    "                term = jnp.einsum('kj,...j->...k', basis, grads[i])\n",
    "                rate = rate - c * term\n",
    "            return rate\n",
    "\n",
    "        def eval_implicit(u, lap, params):\n",
    "            # Implicit Diffusion/Decay: eps*lap - V*u\n",
    "            rate = jnp.zeros_like(u)\n",
    "            if 'epsilon' in params: rate += params['epsilon'] * lap\n",
    "            if 'V' in params: rate -= params['V'] * u\n",
    "            return rate\n",
    "\n",
    "        # 3. The Master Step\n",
    "        def step_fn(u_curr, params, dt, step_idx):\n",
    "            # --- A. PHYSICS (Matrix-Free Hybrid) ---\n",
    "            \n",
    "            # 1. Explicit MacCormack (Advection)\n",
    "            gf, gb, lap = self.manifold.gradients(u_curr)\n",
    "            \n",
    "            # Predict\n",
    "            k1 = eval_advection(u_curr, gf, params)\n",
    "            u_p = u_curr + k1 * dt\n",
    "            \n",
    "            # Correct\n",
    "            gf_p, gb_p, _ = self.manifold.gradients(u_p)\n",
    "            k2 = eval_advection(u_p, gb_p, params)\n",
    "            \n",
    "            u_adv = 0.5 * (u_curr + u_p + k2 * dt)\n",
    "            \n",
    "            # 2. Implicit CG (Diffusion)\n",
    "            def linear_op(x_flat):\n",
    "                x = x_flat.reshape(u_curr.shape)\n",
    "                _, _, lap_x = self.manifold.gradients(x)\n",
    "                rate = eval_implicit(x, lap_x, params)\n",
    "                return (x - dt * rate).ravel()\n",
    "            \n",
    "            u_flat = u_adv.ravel()\n",
    "            # If eps=0, this is Identity solve (instant)\n",
    "            u_next_flat, _ = spla.cg(linear_op, u_flat, x0=u_flat, tol=1e-5, maxiter=20)\n",
    "            u_next = u_next_flat.reshape(u_curr.shape)\n",
    "            \n",
    "            # --- B. SOURCES ---\n",
    "            t = step_idx * dt\n",
    "            for src_fn in source_fns:\n",
    "                u_next = u_next + src_fn(params, t, step_idx, self.manifold.coordinates)\n",
    "                \n",
    "            # --- C. BOUNDARIES ---\n",
    "            for bc_fn in bc_fns:\n",
    "                u_next = bc_fn(u_next)\n",
    "                \n",
    "            return u_next\n",
    "\n",
    "        return step_fn\n",
    "\n",
    "    # (Inlined Source/BC compilers for completeness)\n",
    "    def _compile_source(self, src):\n",
    "        # ... (Same logic as before) ...\n",
    "        amp = src.temporal_profile.amplitude\n",
    "        t_center = src.temporal_profile.center_step\n",
    "        t_width = src.temporal_profile.width_step\n",
    "        sigma_sq = src.spatial_sigma\n",
    "        \n",
    "        pos_name = src.trajectory.start_pos.name\n",
    "        vel_name = src.trajectory.velocity.name\n",
    "        \n",
    "        def kernel(params, t, i, coords):\n",
    "            X, Y = coords\n",
    "            p0, v = params[pos_name], params[vel_name]\n",
    "            x_c = p0[0] + v[0] * t\n",
    "            y_c = p0[1] + v[1] * t\n",
    "            \n",
    "            dist_sq = (X - x_c)**2 + (Y - y_c)**2\n",
    "            val = jnp.exp(-dist_sq / sigma_sq) * \\\n",
    "                  jnp.exp(-(i - t_center)**2 / t_width) * amp * 0.0001 # dt hardcoded or passed?\n",
    "            \n",
    "            zeros = jnp.zeros_like(val)\n",
    "            return jnp.stack([val, zeros, zeros, zeros], axis=-1)\n",
    "        return kernel\n",
    "\n",
    "    def _compile_bc(self, bc):\n",
    "        return self.manifold.enforce_boundaries\n",
    "\n",
    "# --- 2. CONFIGURATION ---\n",
    "GRID_SIZE = 100\n",
    "DX = 0.1\n",
    "DT = 0.0001\n",
    "STEPS = 1200\n",
    "\n",
    "algebra = MatrixAlgebra(2, 0)\n",
    "manifold = CartesianBox((GRID_SIZE, GRID_SIZE), DX)\n",
    "\n",
    "# --- 3. DECLARATIVE SETUP (The User's View) ---\n",
    "Psi = Field(\"Psi\")\n",
    "c, V, eps = Parameter(\"c\"), Parameter(\"V\"), Parameter(\"epsilon\")\n",
    "pos, vel = Parameter(\"pos\"), Parameter(\"vel\")\n",
    "\n",
    "# Equation (Symbolic only now, but guides the architecture)\n",
    "eq = Eq(dt(Psi), -(c * grad(Psi)) + eps * laplacian(Psi) - V * Psi)\n",
    "\n",
    "source = MovingSpotlight(\n",
    "    field=Psi,\n",
    "    trajectory=LinearTrajectory(start_pos=pos, velocity=vel),\n",
    "    spatial_sigma=4.5,\n",
    "    temporal_profile=GaussianPulse(center_step=50, width_step=800.0, amplitude=100.0)\n",
    ")\n",
    "problem = Problem(eq, [DirichletBC(Psi)], [source])\n",
    "\n",
    "# --- 4. COMPILATION & EXECUTION ---\n",
    "solver = RobustHybridSolver(algebra, manifold)\n",
    "step_fn = solver.compile_step(problem)\n",
    "\n",
    "print(\"--- Robust Hybrid Solver Compiled ---\")\n",
    "\n",
    "@jax.jit\n",
    "def run_sim(params_dict, hyper_params):\n",
    "    u = jnp.zeros((GRID_SIZE, GRID_SIZE, algebra.dim))\n",
    "    p = {**params_dict, **hyper_params}\n",
    "    \n",
    "    def body(carry, i):\n",
    "        u_next = step_fn(carry, p, DT, i)\n",
    "        return u_next, u_next[..., 0] # Return full state + Scalar for recording\n",
    "\n",
    "    _, history = lax.scan(body, u, jnp.arange(STEPS))\n",
    "    return history\n",
    "\n",
    "def solve_robust():\n",
    "    # TRUTH\n",
    "    TRUE_PARAMS = {'pos': jnp.array([3.0, 7.0]), 'vel': jnp.array([40.0, -20.0]), 'c': 343.0, 'V': 0.5}\n",
    "    print(\"Generating Ground Truth...\")\n",
    "    true_hist = run_sim(TRUE_PARAMS, {'epsilon': 0.0})\n",
    "    \n",
    "    SENSORS = jnp.array([[90, 10], [90, 90], [10, 10], [10, 90]])\n",
    "    obs_data = true_hist[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "    \n",
    "    # INVERSE\n",
    "    guess = {'pos': jnp.array([5.0, 5.0]), 'vel': jnp.array([0.0, 0.0]), 'c': 300.0, 'V': 0.0}\n",
    "    optimizer = optax.chain(optax.clip_by_global_norm(1.0), optax.multi_transform(\n",
    "        {'pos': optax.adam(0.1), 'vel': optax.adam(5.0), 'c': optax.adam(1.0), 'V': optax.adam(0.5)},\n",
    "        {'pos':'pos', 'vel':'vel', 'c':'c', 'V':'V'}))\n",
    "    opt_state = optimizer.init(guess)\n",
    "    \n",
    "    @jax.jit\n",
    "    def update(state, guess, eps):\n",
    "        def loss(p):\n",
    "            sim = run_sim(p, {'epsilon': eps})\n",
    "            dat = sim[:, SENSORS[:,0], SENSORS[:,1]]\n",
    "            safe = 1e-6\n",
    "            sim_n = (dat - jnp.mean(dat, 0)) / (jnp.std(dat, 0) + safe)\n",
    "            obs_n = (obs_data - jnp.mean(obs_data, 0)) / (jnp.std(obs_data, 0) + safe)\n",
    "            pb = jnp.sum(jnp.maximum(0, -p['pos'])) + jnp.sum(jnp.maximum(0, p['pos'] - 10.0))\n",
    "            return (1.0 - jnp.mean(sim_n * obs_n)) + pb\n",
    "        l, g = value_and_grad(loss)(guess)\n",
    "        u, s = optimizer.update(g, state, guess)\n",
    "        return l, optax.apply_updates(guess, u), s\n",
    "\n",
    "    print(\"\\n--- Starting Robust Precision Search ---\")\n",
    "    # Using small epsilon steps to guide it\n",
    "    for stage, eps in enumerate([2.0, 0.5, 0.0]):\n",
    "        print(f\"\\n>>> STAGE {stage} (Epsilon={eps}) <<<\")\n",
    "        for i in range(201):\n",
    "            loss, new_guess, opt_state = update(opt_state, guess, eps)\n",
    "            \n",
    "            d_vel = jnp.linalg.norm(new_guess['vel'] - guess['vel'])\n",
    "            guess = new_guess\n",
    "            \n",
    "            if i > 20 and d_vel < 0.01:\n",
    "                print(f\"  [CONVERGED] Iter {i} | Vel Delta={d_vel:.4f}\")\n",
    "                print(f\"  Current: Vel={guess['vel']} | V={guess['V']:.3f}\")\n",
    "                break\n",
    "            if i % 20 == 0:\n",
    "                print(f\"  Iter {i:3d}: Loss={loss:.4f} | Vel={guess['vel']} | V={guess['V']:.3f}\")\n",
    "    return guess\n",
    "\n",
    "final = solve_robust()\n",
    "print(\"\\n--- FINAL RESULT ---\")\n",
    "print(f\"Rec Pos: {final['pos']}\")\n",
    "print(f\"Rec Vel: {final['vel']}\")\n",
    "print(f\"Rec V  : {final['V']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bde743-edcd-4791-a589-f4f75d4ba064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
